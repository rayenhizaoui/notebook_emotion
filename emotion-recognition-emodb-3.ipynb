{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaf6b58",
   "metadata": {
    "papermill": {
     "duration": 0.004653,
     "end_time": "2025-05-08T11:58:21.161199",
     "exception": false,
     "start_time": "2025-05-08T11:58:21.156546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reconnaissance des Émotions Audio avec EmoDB et ResNet-50\n",
    "\n",
    "Ce notebook implémente un pipeline complet pour la reconnaissance des émotions à partir de données audio du dataset EmoDB. Les étapes comprennent :\n",
    "1. Téléchargement et préparation du dataset EmoDB.\n",
    "2. Prétraitement audio : rééchantillonnage, padding.\n",
    "3. Extraction de caractéristiques : conversion en mel-spectrogrammes.\n",
    "4. Normalisation des mel-spectrogrammes.\n",
    "5. Configuration et entraînement d'un modèle ResNet-50 pré-entraîné.\n",
    "6. Évaluation du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d1a32",
   "metadata": {
    "papermill": {
     "duration": 0.003706,
     "end_time": "2025-05-08T11:58:21.168957",
     "exception": false,
     "start_time": "2025-05-08T11:58:21.165251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191ddf1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:58:21.177580Z",
     "iopub.status.busy": "2025-05-08T11:58:21.177316Z",
     "iopub.status.idle": "2025-05-08T11:59:32.984156Z",
     "shell.execute_reply": "2025-05-08T11:59:32.983424Z"
    },
    "papermill": {
     "duration": 71.812985,
     "end_time": "2025-05-08T11:59:32.985602",
     "exception": false,
     "start_time": "2025-05-08T11:58:21.172617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\r\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\r\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.1)\r\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\r\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa gdown soundfile scikit-learn torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ebd0a",
   "metadata": {
    "papermill": {
     "duration": 0.022766,
     "end_time": "2025-05-08T11:59:33.031842",
     "exception": false,
     "start_time": "2025-05-08T11:59:33.009076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Imports et Configuration Initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9cc973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:59:33.079469Z",
     "iopub.status.busy": "2025-05-08T11:59:33.079153Z",
     "iopub.status.idle": "2025-05-08T11:59:43.723223Z",
     "shell.execute_reply": "2025-05-08T11:59:43.722437Z"
    },
    "papermill": {
     "duration": 10.669556,
     "end_time": "2025-05-08T11:59:43.724437",
     "exception": false,
     "start_time": "2025-05-08T11:59:33.054881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configuration pour la reproductibilité\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Déterminer le périphérique (GPU si disponible, sinon CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6364c",
   "metadata": {
    "papermill": {
     "duration": 0.022851,
     "end_time": "2025-05-08T11:59:43.770720",
     "exception": false,
     "start_time": "2025-05-08T11:59:43.747869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Chargement et Préparation du Dataset EmoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea61c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:59:43.817566Z",
     "iopub.status.busy": "2025-05-08T11:59:43.817100Z",
     "iopub.status.idle": "2025-05-08T12:00:52.980234Z",
     "shell.execute_reply": "2025-05-08T12:00:52.979325Z"
    },
    "papermill": {
     "duration": 69.188351,
     "end_time": "2025-05-08T12:00:52.981693",
     "exception": false,
     "start_time": "2025-05-08T11:59:43.793342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EmoDB dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: http://emodb.bilderbar.info/download/download.zip\n",
      "To: /kaggle/working/emodb.zip\n",
      "100%|██████████| 40.6M/40.6M [01:07<00:00, 598kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 'emodb_extracted/wav' to 'emodb/wav'\n",
      "Warning: Unexpected files/folders in emodb_extracted: ['labsilb', 'lablaut', 'erkennung.txt', 'erklaerung.txt', 'silb']. Manual cleanup might be needed.\n",
      "Nombre de fichiers WAV : 535\n"
     ]
    }
   ],
   "source": [
    "# Étape 1 : Chargement des données\n",
    "# Télécharger le dataset EmoDB et organiser les fichiers\n",
    "if not os.path.exists('emodb/wav'): # Vérifie si le dossier final existe\n",
    "    print(\"Downloading EmoDB dataset...\")\n",
    "    url = 'http://emodb.bilderbar.info/download/download.zip'\n",
    "    output_zip = 'emodb.zip'\n",
    "    gdown.download(url, output_zip, quiet=False)\n",
    "    \n",
    "    # Créer le répertoire de base 'emodb' s'il n'existe pas\n",
    "    if not os.path.exists('emodb'):\n",
    "        os.makedirs('emodb')\n",
    "        \n",
    "    # Décompresser le fichier zip\n",
    "    with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall('emodb_extracted') # Extraire dans un dossier temporaire\n",
    "    \n",
    "    # EmoDB extrait les fichiers dans un sous-dossier 'wav', nous le déplaçons/renommons pour correspondre à la structure attendue\n",
    "    source_wav_dir = os.path.join('emodb_extracted', 'wav')\n",
    "    target_wav_dir = os.path.join('emodb', 'wav')\n",
    "    \n",
    "    if os.path.exists(source_wav_dir):\n",
    "        if not os.path.exists(target_wav_dir):\n",
    "             os.makedirs(os.path.dirname(target_wav_dir), exist_ok=True) # Assure que 'emodb' existe\n",
    "        os.rename(source_wav_dir, target_wav_dir)\n",
    "        print(f\"Moved '{source_wav_dir}' to '{target_wav_dir}'\")\n",
    "    else:\n",
    "        print(f\"Error: Source WAV directory '{source_wav_dir}' not found after extraction.\")\n",
    "        \n",
    "    # Nettoyer les dossiers intermédiaires et le zip\n",
    "    if os.path.exists('emodb_extracted'):\n",
    "        # Vérifier s'il reste des fichiers/dossiers inattendus avant de supprimer\n",
    "        remaining_items = os.listdir('emodb_extracted')\n",
    "        if not remaining_items or (len(remaining_items) == 1 and remaining_items[0] == 'wav' and not os.path.exists(source_wav_dir)):\n",
    "            os.rmdir('emodb_extracted') # Supprime si vide ou si 'wav' a été déplacé\n",
    "        elif os.path.isdir(os.path.join('emodb_extracted', 'lab')) and len(remaining_items) <=2 : # Cas typique avec 'lab'\n",
    "            import shutil\n",
    "            shutil.rmtree('emodb_extracted') # Supprime le dossier et son contenu (comme 'lab')\n",
    "            print(\"Cleaned up 'emodb_extracted' directory.\")\n",
    "        else:\n",
    "            print(f\"Warning: Unexpected files/folders in emodb_extracted: {remaining_items}. Manual cleanup might be needed.\")\n",
    "\n",
    "    if os.path.exists(output_zip):\n",
    "        os.remove(output_zip)\n",
    "else:\n",
    "    print(\"EmoDB dataset (emodb/wav) already found.\")\n",
    "\n",
    "# Chemin vers les fichiers WAV\n",
    "wav_dir = 'emodb/wav'\n",
    "if not os.path.exists(wav_dir) or not os.listdir(wav_dir):\n",
    "    print(f\"Error: WAV directory '{wav_dir}' is empty or does not exist. Please check the download and extraction steps.\")\n",
    "    # exit() # En Colab, on évite exit() pour ne pas tuer le kernel, mais on signale l'erreur\n",
    "else:\n",
    "    wav_files = [f for f in os.listdir(wav_dir) if f.endswith('.wav')]\n",
    "    print(f\"Nombre de fichiers WAV : {len(wav_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e8699e",
   "metadata": {
    "papermill": {
     "duration": 0.032189,
     "end_time": "2025-05-08T12:00:53.101627",
     "exception": false,
     "start_time": "2025-05-08T12:00:53.069438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Prétraitement Audio : Rééchantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34fd4461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:00:53.176417Z",
     "iopub.status.busy": "2025-05-08T12:00:53.175697Z",
     "iopub.status.idle": "2025-05-08T12:01:09.399674Z",
     "shell.execute_reply": "2025-05-08T12:01:09.398843Z"
    },
    "papermill": {
     "duration": 16.259491,
     "end_time": "2025-05-08T12:01:09.401010",
     "exception": false,
     "start_time": "2025-05-08T12:00:53.141519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling files...\n",
      "Resampling complete.\n"
     ]
    }
   ],
   "source": [
    "new_sr = 22050 # Fréquence d'échantillonnage cible standard\n",
    "resampled_dir = 'emodb/resampled'\n",
    "os.makedirs(resampled_dir, exist_ok=True)\n",
    "\n",
    "print(\"Resampling files...\")\n",
    "if 'wav_files' in locals(): # S'assurer que wav_files est défini\n",
    "    for wav_file in wav_files:\n",
    "        file_path = os.path.join(wav_dir, wav_file)\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            audio_resampled = librosa.resample(y=audio, orig_sr=sr, target_sr=new_sr)\n",
    "            sf.write(os.path.join(resampled_dir, wav_file), audio_resampled, new_sr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {wav_file} during resampling: {e}\")\n",
    "    print(\"Resampling complete.\")\n",
    "else:\n",
    "    print(\"wav_files not defined. Skipping resampling. Check previous cell for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd7934",
   "metadata": {
    "papermill": {
     "duration": 0.026987,
     "end_time": "2025-05-08T12:01:09.456756",
     "exception": false,
     "start_time": "2025-05-08T12:01:09.429769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Prétraitement Audio : Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48ac1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:09.513226Z",
     "iopub.status.busy": "2025-05-08T12:01:09.512324Z",
     "iopub.status.idle": "2025-05-08T12:01:14.693367Z",
     "shell.execute_reply": "2025-05-08T12:01:14.692555Z"
    },
    "papermill": {
     "duration": 5.210088,
     "end_time": "2025-05-08T12:01:14.694641",
     "exception": false,
     "start_time": "2025-05-08T12:01:09.484553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding files...\n",
      "Padding complete.\n"
     ]
    }
   ],
   "source": [
    "target_duration = 10  # secondes\n",
    "target_samples = target_duration * new_sr\n",
    "padded_dir = 'emodb/padded'\n",
    "os.makedirs(padded_dir, exist_ok=True)\n",
    "\n",
    "print(\"Padding files...\")\n",
    "if 'wav_files' in locals(): # S'assurer que wav_files est défini\n",
    "    for wav_file in wav_files: # Assurez-vous que wav_files contient les noms de base des fichiers\n",
    "        file_path = os.path.join(resampled_dir, wav_file)\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=new_sr)\n",
    "            current_samples = len(audio)\n",
    "            if current_samples < target_samples:\n",
    "                padding_needed = target_samples - current_samples\n",
    "                padding = np.zeros(padding_needed)\n",
    "                audio_padded = np.concatenate((audio, padding))\n",
    "            else:\n",
    "                audio_padded = audio[:target_samples]\n",
    "            sf.write(os.path.join(padded_dir, wav_file), audio_padded, new_sr)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {wav_file} during padding: {e}\")\n",
    "    print(\"Padding complete.\")\n",
    "else:\n",
    "    print(\"wav_files not defined. Skipping padding. Check previous cells for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a581836",
   "metadata": {
    "papermill": {
     "duration": 0.025841,
     "end_time": "2025-05-08T12:01:14.747548",
     "exception": false,
     "start_time": "2025-05-08T12:01:14.721707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Extraction de Caractéristiques : Mel-Spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317b64ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:14.800745Z",
     "iopub.status.busy": "2025-05-08T12:01:14.800489Z",
     "iopub.status.idle": "2025-05-08T12:01:22.884380Z",
     "shell.execute_reply": "2025-05-08T12:01:22.883491Z"
    },
    "papermill": {
     "duration": 8.112108,
     "end_time": "2025-05-08T12:01:22.885662",
     "exception": false,
     "start_time": "2025-05-08T12:01:14.773554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to mel-spectrograms...\n",
      "Mel-spectrogram conversion complete.\n"
     ]
    }
   ],
   "source": [
    "hop_length = 256\n",
    "win_length = 1024\n",
    "n_fft = win_length \n",
    "n_mels = 80\n",
    "mel_dir = 'emodb/mel_spectrograms'\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "\n",
    "print(\"Converting to mel-spectrograms...\")\n",
    "if 'wav_files' in locals(): # S'assurer que wav_files est défini\n",
    "    for wav_file in wav_files:\n",
    "        file_path = os.path.join(padded_dir, wav_file)\n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=new_sr)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, win_length=win_length, n_mels=n_mels)\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            np.save(os.path.join(mel_dir, wav_file.replace('.wav', '.npy')), mel_spec_db)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {wav_file} during mel-spectrogram conversion: {e}\")\n",
    "    print(\"Mel-spectrogram conversion complete.\")\n",
    "else:\n",
    "    print(\"wav_files not defined. Skipping mel-spectrogram conversion. Check previous cells for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5474e7",
   "metadata": {
    "papermill": {
     "duration": 0.026486,
     "end_time": "2025-05-08T12:01:22.941922",
     "exception": false,
     "start_time": "2025-05-08T12:01:22.915436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Normalisation des Mel-Spectrogrammes (Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b15293cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:22.999733Z",
     "iopub.status.busy": "2025-05-08T12:01:22.998852Z",
     "iopub.status.idle": "2025-05-08T12:01:23.478531Z",
     "shell.execute_reply": "2025-05-08T12:01:23.477765Z"
    },
    "papermill": {
     "duration": 0.509931,
     "end_time": "2025-05-08T12:01:23.479742",
     "exception": false,
     "start_time": "2025-05-08T12:01:22.969811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing mel-spectrograms...\n",
      "Normalization complete.\n"
     ]
    }
   ],
   "source": [
    "normalized_dir = 'emodb/normalized_mel'\n",
    "os.makedirs(normalized_dir, exist_ok=True)\n",
    "\n",
    "print(\"Normalizing mel-spectrograms...\")\n",
    "if os.path.exists(mel_dir):\n",
    "    mel_npy_files = [f for f in os.listdir(mel_dir) if f.endswith('.npy')]\n",
    "    if mel_npy_files:\n",
    "        for mel_file in mel_npy_files:\n",
    "            file_path = os.path.join(mel_dir, mel_file)\n",
    "            try:\n",
    "                mel_spec = np.load(file_path)\n",
    "                mean = np.mean(mel_spec)\n",
    "                std = np.std(mel_spec)\n",
    "                if std == 0: # Éviter la division par zéro\n",
    "                    mel_spec_normalized = mel_spec - mean\n",
    "                else:\n",
    "                    mel_spec_normalized = (mel_spec - mean) / std\n",
    "                np.save(os.path.join(normalized_dir, mel_file), mel_spec_normalized)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {mel_file} during normalization: {e}\")\n",
    "        print(\"Normalization complete.\")\n",
    "    else:\n",
    "        print(f\"No .npy files found in {mel_dir}. Skipping normalization.\")\n",
    "else:\n",
    "    print(f\"Mel directory {mel_dir} not found. Skipping normalization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74027602",
   "metadata": {
    "papermill": {
     "duration": 0.026388,
     "end_time": "2025-05-08T12:01:23.533646",
     "exception": false,
     "start_time": "2025-05-08T12:01:23.507258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Vérification et Préparation des Données pour le Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23b179a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:23.589749Z",
     "iopub.status.busy": "2025-05-08T12:01:23.589133Z",
     "iopub.status.idle": "2025-05-08T12:01:23.595501Z",
     "shell.execute_reply": "2025-05-08T12:01:23.594778Z"
    },
    "papermill": {
     "duration": 0.035644,
     "end_time": "2025-05-08T12:01:23.596657",
     "exception": false,
     "start_time": "2025-05-08T12:01:23.561013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme du mel-spectrogramme normalisé (03a02Ta.npy) : (80, 862)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(normalized_dir) and os.listdir(normalized_dir):\n",
    "    sample_file = os.listdir(normalized_dir)[0]\n",
    "    sample_mel = np.load(os.path.join(normalized_dir, sample_file))\n",
    "    print(f\"Forme du mel-spectrogramme normalisé ({sample_file}) : {sample_mel.shape}\")\n",
    "else:\n",
    "    print(f\"Warning: No normalized mel-spectrograms found in {normalized_dir}.\")\n",
    "\n",
    "# Définir les émotions et le mappage pour EmoDB\n",
    "# Codes EmoDB: W(Wut/Anger), L(Langeweile/Boredom), E(Ekel/Disgust), A(Angst/Fear), F(Freude/Happiness), T(Trauer/Sadness), N(Neutral)\n",
    "emotions_map = {\n",
    "    'W': 'angry',\n",
    "    'L': 'boredom',\n",
    "    'E': 'disgust',\n",
    "    'A': 'fear',\n",
    "    'F': 'happy',\n",
    "    'T': 'sad',\n",
    "    'N': 'neutral'\n",
    "}\n",
    "# Liste ordonnée des émotions pour l'encodeur et le modèle\n",
    "emotion_list = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust', 'boredom']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd06571",
   "metadata": {
    "papermill": {
     "duration": 0.026584,
     "end_time": "2025-05-08T12:01:23.650359",
     "exception": false,
     "start_time": "2025-05-08T12:01:23.623775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Chargement des Données et Encodage des Étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44bc00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:23.706167Z",
     "iopub.status.busy": "2025-05-08T12:01:23.705631Z",
     "iopub.status.idle": "2025-05-08T12:01:23.884039Z",
     "shell.execute_reply": "2025-05-08T12:01:23.883254Z"
    },
    "papermill": {
     "duration": 0.207635,
     "end_time": "2025-05-08T12:01:23.885133",
     "exception": false,
     "start_time": "2025-05-08T12:01:23.677498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for model...\n",
      "Total number of loaded files for model: 535\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels_str = [] # Stocker les étiquettes textuelles\n",
    "print(\"Loading data for model...\")\n",
    "if os.path.exists(normalized_dir):\n",
    "    normalized_npy_files = [f for f in os.listdir(normalized_dir) if f.endswith('.npy')]\n",
    "    if normalized_npy_files:\n",
    "        for file in normalized_npy_files:\n",
    "            # Le nom du fichier EmoDB est structuré, par exemple: 03a01Fa.wav\n",
    "            # Le 5ème caractère (index 5 pour '03a01Fa.npy') est le code de l'émotion\n",
    "            if len(file) > 5: # Vérification de base de la longueur du nom de fichier\n",
    "                emotion_code = file[5] \n",
    "                emotion = emotions_map.get(emotion_code)\n",
    "\n",
    "                if emotion:\n",
    "                    mel_spec = np.load(os.path.join(normalized_dir, file))\n",
    "                    data.append(mel_spec)\n",
    "                    labels_str.append(emotion)\n",
    "                else:\n",
    "                    print(f\"Skipped file: {file} - Unknown emotion code: {emotion_code}\")\n",
    "            else:\n",
    "                print(f\"Skipped file: {file} - Filename too short to extract emotion code.\")\n",
    "        print(f\"Total number of loaded files for model: {len(data)}\")\n",
    "    else:\n",
    "        print(f\"No .npy files found in {normalized_dir} for model loading.\")\n",
    "else:\n",
    "    print(f\"Normalized directory {normalized_dir} not found. Cannot load data for model.\")\n",
    "\n",
    "if not data:\n",
    "    print(\"Error: No data loaded for the model. Further steps might fail.\")\n",
    "    # exit() # En Colab, on évite exit()\n",
    "else:\n",
    "    # Encoder les étiquettes\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(emotion_list) # Adapter l'encodeur à la liste complète des émotions\n",
    "    labels_encoded = label_encoder.transform(labels_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a94a11",
   "metadata": {
    "papermill": {
     "duration": 0.026692,
     "end_time": "2025-05-08T12:01:23.938932",
     "exception": false,
     "start_time": "2025-05-08T12:01:23.912240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. Définition du Dataset Personnalisé PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab19fe79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:23.994658Z",
     "iopub.status.busy": "2025-05-08T12:01:23.994377Z",
     "iopub.status.idle": "2025-05-08T12:01:23.998909Z",
     "shell.execute_reply": "2025-05-08T12:01:23.998391Z"
    },
    "papermill": {
     "duration": 0.034065,
     "end_time": "2025-05-08T12:01:24.000037",
     "exception": false,
     "start_time": "2025-05-08T12:01:23.965972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmoDBDataset(Dataset):\n",
    "    def __init__(self, data, labels_encoded):\n",
    "        self.data = data\n",
    "        self.labels = labels_encoded # Stocker les étiquettes encodées numériquement\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel_spec = torch.tensor(self.data[idx], dtype=torch.float32).unsqueeze(0)  # Ajouter une dimension de canal\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long) # Retourner l'indice de classe\n",
    "        return mel_spec, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddf58fb",
   "metadata": {
    "papermill": {
     "duration": 0.027646,
     "end_time": "2025-05-08T12:01:24.055559",
     "exception": false,
     "start_time": "2025-05-08T12:01:24.027913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11. Création des Datasets et DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5f9d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:24.111744Z",
     "iopub.status.busy": "2025-05-08T12:01:24.111170Z",
     "iopub.status.idle": "2025-05-08T12:01:24.135253Z",
     "shell.execute_reply": "2025-05-08T12:01:24.134582Z"
    },
    "papermill": {
     "duration": 0.053201,
     "end_time": "2025-05-08T12:01:24.136541",
     "exception": false,
     "start_time": "2025-05-08T12:01:24.083340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: Train 428, Validation 107\n"
     ]
    }
   ],
   "source": [
    "if 'data' in locals() and len(data) > 0:\n",
    "    dataset = EmoDBDataset(data, labels_encoded)\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de validation\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    \n",
    "    if train_size == 0 or val_size == 0:\n",
    "        print(f\"Error: Not enough data to split. Train size: {train_size}, Val size: {val_size}. Loaded: {len(dataset)}\")\n",
    "        # exit() # En Colab, on évite exit()\n",
    "    else:\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "        # Créer des DataLoaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "        print(f\"Dataset split: Train {len(train_dataset)}, Validation {len(val_dataset)}\")\n",
    "else:\n",
    "    print(\"Data not available for creating datasets. Check previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7563e6",
   "metadata": {
    "papermill": {
     "duration": 0.027521,
     "end_time": "2025-05-08T12:01:24.193069",
     "exception": false,
     "start_time": "2025-05-08T12:01:24.165548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 12. Configuration du Modèle ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e831f2ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:24.251968Z",
     "iopub.status.busy": "2025-05-08T12:01:24.251380Z",
     "iopub.status.idle": "2025-05-08T12:01:26.041878Z",
     "shell.execute_reply": "2025-05-08T12:01:26.041021Z"
    },
    "papermill": {
     "duration": 1.821594,
     "end_time": "2025-05-08T12:01:26.043037",
     "exception": false,
     "start_time": "2025-05-08T12:01:24.221443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 131MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ResNet50 with ResNet50_Weights.IMAGENET1K_V1\n",
      "Model configured:\n",
      "  Input channels for conv1: 1\n",
      "  Output features for fc: 7\n"
     ]
    }
   ],
   "source": [
    "# Utiliser weights=models.ResNet50_Weights.IMAGENET1K_V1 pour les versions plus récentes de torchvision\n",
    "try:\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    print(\"Using ResNet50 with ResNet50_Weights.IMAGENET1K_V1\")\n",
    "except TypeError:\n",
    "    print(\"Using deprecated 'pretrained=True' for ResNet50.\")\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Adapter pour 1 canal (mel-spectrogrammes)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(emotion_list))  # Adapter pour le nombre d'émotions\n",
    "model = model.to(device) # Déplacer le modèle sur le périphérique\n",
    "\n",
    "print(\"Model configured:\")\n",
    "print(f\"  Input channels for conv1: {model.conv1.in_channels}\")\n",
    "print(f\"  Output features for fc: {model.fc.out_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294ee3b",
   "metadata": {
    "papermill": {
     "duration": 0.027299,
     "end_time": "2025-05-08T12:01:26.098018",
     "exception": false,
     "start_time": "2025-05-08T12:01:26.070719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 13. Définition de la Fonction de Perte et de l'Optimiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6074669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:26.153998Z",
     "iopub.status.busy": "2025-05-08T12:01:26.153732Z",
     "iopub.status.idle": "2025-05-08T12:01:26.158880Z",
     "shell.execute_reply": "2025-05-08T12:01:26.158231Z"
    },
    "papermill": {
     "duration": 0.034654,
     "end_time": "2025-05-08T12:01:26.159901",
     "exception": false,
     "start_time": "2025-05-08T12:01:26.125247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function and optimizer defined.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "print(\"Loss function and optimizer defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7775183a",
   "metadata": {
    "papermill": {
     "duration": 0.02805,
     "end_time": "2025-05-08T12:01:26.216990",
     "exception": false,
     "start_time": "2025-05-08T12:01:26.188940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 14. Fonction d'Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4973ca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:26.273019Z",
     "iopub.status.busy": "2025-05-08T12:01:26.272506Z",
     "iopub.status.idle": "2025-05-08T12:01:26.278992Z",
     "shell.execute_reply": "2025-05-08T12:01:26.278472Z"
    },
    "papermill": {
     "duration": 0.035883,
     "end_time": "2025-05-08T12:01:26.280082",
     "exception": false,
     "start_time": "2025-05-08T12:01:26.244199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_fn(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    print(f\"\\nStarting training for {epochs} epochs on {device}...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for mel_specs, labels in train_loader:\n",
    "            mel_specs, labels = mel_specs.to(device), labels.to(device) # Déplacer les données\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mel_specs)\n",
    "            loss = criterion(outputs, labels) # labels sont maintenant des indices de classe\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * mel_specs.size(0)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for mel_specs, labels in val_loader:\n",
    "                mel_specs, labels = mel_specs.to(device), labels.to(device)\n",
    "                outputs = model(mel_specs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * mel_specs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f503859",
   "metadata": {
    "papermill": {
     "duration": 0.027485,
     "end_time": "2025-05-08T12:01:26.335368",
     "exception": false,
     "start_time": "2025-05-08T12:01:26.307883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 15. Exécution de l'Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1cf5bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:01:26.393363Z",
     "iopub.status.busy": "2025-05-08T12:01:26.392758Z",
     "iopub.status.idle": "2025-05-08T12:46:55.109103Z",
     "shell.execute_reply": "2025-05-08T12:46:55.108290Z"
    },
    "papermill": {
     "duration": 2728.746783,
     "end_time": "2025-05-08T12:46:55.110538",
     "exception": false,
     "start_time": "2025-05-08T12:01:26.363755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 800 epochs on cuda...\n",
      "Epoch 1/800, Train Loss: 1.7092, Val Loss: 1.8468, Val Accuracy: 26.17%\n",
      "Epoch 2/800, Train Loss: 1.1117, Val Loss: 1.6072, Val Accuracy: 32.71%\n",
      "Epoch 3/800, Train Loss: 0.5636, Val Loss: 1.7898, Val Accuracy: 38.32%\n",
      "Epoch 4/800, Train Loss: 0.2531, Val Loss: 1.1773, Val Accuracy: 61.68%\n",
      "Epoch 5/800, Train Loss: 0.1245, Val Loss: 0.9882, Val Accuracy: 64.49%\n",
      "Epoch 6/800, Train Loss: 0.1287, Val Loss: 0.6434, Val Accuracy: 79.44%\n",
      "Epoch 7/800, Train Loss: 0.0880, Val Loss: 0.9480, Val Accuracy: 72.90%\n",
      "Epoch 8/800, Train Loss: 0.1043, Val Loss: 1.1125, Val Accuracy: 67.29%\n",
      "Epoch 9/800, Train Loss: 0.0761, Val Loss: 1.6932, Val Accuracy: 53.27%\n",
      "Epoch 10/800, Train Loss: 0.0896, Val Loss: 0.9366, Val Accuracy: 73.83%\n",
      "Epoch 11/800, Train Loss: 0.1076, Val Loss: 1.2620, Val Accuracy: 65.42%\n",
      "Epoch 12/800, Train Loss: 0.1468, Val Loss: 1.2042, Val Accuracy: 64.49%\n",
      "Epoch 13/800, Train Loss: 0.0855, Val Loss: 0.8908, Val Accuracy: 74.77%\n",
      "Epoch 14/800, Train Loss: 0.0619, Val Loss: 0.8233, Val Accuracy: 71.96%\n",
      "Epoch 15/800, Train Loss: 0.0398, Val Loss: 0.8773, Val Accuracy: 73.83%\n",
      "Epoch 16/800, Train Loss: 0.0277, Val Loss: 0.7502, Val Accuracy: 78.50%\n",
      "Epoch 17/800, Train Loss: 0.0118, Val Loss: 0.6102, Val Accuracy: 78.50%\n",
      "Epoch 18/800, Train Loss: 0.0126, Val Loss: 0.6214, Val Accuracy: 79.44%\n",
      "Epoch 19/800, Train Loss: 0.0060, Val Loss: 0.6845, Val Accuracy: 79.44%\n",
      "Epoch 20/800, Train Loss: 0.0051, Val Loss: 0.6288, Val Accuracy: 81.31%\n",
      "Epoch 21/800, Train Loss: 0.0061, Val Loss: 0.5735, Val Accuracy: 80.37%\n",
      "Epoch 22/800, Train Loss: 0.0045, Val Loss: 0.5825, Val Accuracy: 80.37%\n",
      "Epoch 23/800, Train Loss: 0.0040, Val Loss: 0.6070, Val Accuracy: 77.57%\n",
      "Epoch 24/800, Train Loss: 0.0054, Val Loss: 0.6008, Val Accuracy: 81.31%\n",
      "Epoch 25/800, Train Loss: 0.0047, Val Loss: 0.5486, Val Accuracy: 81.31%\n",
      "Epoch 26/800, Train Loss: 0.0040, Val Loss: 0.6657, Val Accuracy: 81.31%\n",
      "Epoch 27/800, Train Loss: 0.0042, Val Loss: 0.7000, Val Accuracy: 80.37%\n",
      "Epoch 28/800, Train Loss: 0.0028, Val Loss: 0.6609, Val Accuracy: 80.37%\n",
      "Epoch 29/800, Train Loss: 0.0026, Val Loss: 0.6586, Val Accuracy: 77.57%\n",
      "Epoch 30/800, Train Loss: 0.0035, Val Loss: 0.5806, Val Accuracy: 80.37%\n",
      "Epoch 31/800, Train Loss: 0.0024, Val Loss: 0.6442, Val Accuracy: 81.31%\n",
      "Epoch 32/800, Train Loss: 0.0030, Val Loss: 0.6687, Val Accuracy: 81.31%\n",
      "Epoch 33/800, Train Loss: 0.0023, Val Loss: 0.7506, Val Accuracy: 79.44%\n",
      "Epoch 34/800, Train Loss: 0.0024, Val Loss: 0.6879, Val Accuracy: 78.50%\n",
      "Epoch 35/800, Train Loss: 0.0117, Val Loss: 0.6965, Val Accuracy: 74.77%\n",
      "Epoch 36/800, Train Loss: 0.0171, Val Loss: 0.9600, Val Accuracy: 71.96%\n",
      "Epoch 37/800, Train Loss: 0.0218, Val Loss: 0.8223, Val Accuracy: 81.31%\n",
      "Epoch 38/800, Train Loss: 0.0133, Val Loss: 0.7517, Val Accuracy: 81.31%\n",
      "Epoch 39/800, Train Loss: 0.0245, Val Loss: 0.7482, Val Accuracy: 80.37%\n",
      "Epoch 40/800, Train Loss: 0.0208, Val Loss: 0.7091, Val Accuracy: 79.44%\n",
      "Epoch 41/800, Train Loss: 0.0398, Val Loss: 0.6405, Val Accuracy: 81.31%\n",
      "Epoch 42/800, Train Loss: 0.0413, Val Loss: 0.8205, Val Accuracy: 71.96%\n",
      "Epoch 43/800, Train Loss: 0.0220, Val Loss: 1.0649, Val Accuracy: 75.70%\n",
      "Epoch 44/800, Train Loss: 0.0821, Val Loss: 1.0629, Val Accuracy: 70.09%\n",
      "Epoch 45/800, Train Loss: 0.0780, Val Loss: 1.0170, Val Accuracy: 60.75%\n",
      "Epoch 46/800, Train Loss: 0.0806, Val Loss: 1.3395, Val Accuracy: 58.88%\n",
      "Epoch 47/800, Train Loss: 0.1430, Val Loss: 1.3601, Val Accuracy: 65.42%\n",
      "Epoch 48/800, Train Loss: 0.0923, Val Loss: 1.8857, Val Accuracy: 62.62%\n",
      "Epoch 49/800, Train Loss: 0.0588, Val Loss: 1.0930, Val Accuracy: 71.03%\n",
      "Epoch 50/800, Train Loss: 0.0280, Val Loss: 0.5386, Val Accuracy: 82.24%\n",
      "Epoch 51/800, Train Loss: 0.0334, Val Loss: 0.9200, Val Accuracy: 72.90%\n",
      "Epoch 52/800, Train Loss: 0.0285, Val Loss: 0.5381, Val Accuracy: 82.24%\n",
      "Epoch 53/800, Train Loss: 0.0061, Val Loss: 0.4511, Val Accuracy: 87.85%\n",
      "Epoch 54/800, Train Loss: 0.0238, Val Loss: 1.2185, Val Accuracy: 63.55%\n",
      "Epoch 55/800, Train Loss: 0.0567, Val Loss: 0.8170, Val Accuracy: 78.50%\n",
      "Epoch 56/800, Train Loss: 0.1497, Val Loss: 0.9821, Val Accuracy: 67.29%\n",
      "Epoch 57/800, Train Loss: 0.0326, Val Loss: 0.5772, Val Accuracy: 83.18%\n",
      "Epoch 58/800, Train Loss: 0.0239, Val Loss: 1.3423, Val Accuracy: 77.57%\n",
      "Epoch 59/800, Train Loss: 0.1614, Val Loss: 0.9416, Val Accuracy: 69.16%\n",
      "Epoch 60/800, Train Loss: 0.0624, Val Loss: 0.8687, Val Accuracy: 75.70%\n",
      "Epoch 61/800, Train Loss: 0.0380, Val Loss: 0.7375, Val Accuracy: 77.57%\n",
      "Epoch 62/800, Train Loss: 0.0327, Val Loss: 1.2349, Val Accuracy: 68.22%\n",
      "Epoch 63/800, Train Loss: 0.0350, Val Loss: 1.4090, Val Accuracy: 63.55%\n",
      "Epoch 64/800, Train Loss: 0.0239, Val Loss: 0.8927, Val Accuracy: 73.83%\n",
      "Epoch 65/800, Train Loss: 0.0144, Val Loss: 0.7599, Val Accuracy: 77.57%\n",
      "Epoch 66/800, Train Loss: 0.0164, Val Loss: 0.6707, Val Accuracy: 80.37%\n",
      "Epoch 67/800, Train Loss: 0.0076, Val Loss: 0.9117, Val Accuracy: 79.44%\n",
      "Epoch 68/800, Train Loss: 0.0259, Val Loss: 0.9777, Val Accuracy: 72.90%\n",
      "Epoch 69/800, Train Loss: 0.0197, Val Loss: 0.8601, Val Accuracy: 79.44%\n",
      "Epoch 70/800, Train Loss: 0.0294, Val Loss: 0.8192, Val Accuracy: 74.77%\n",
      "Epoch 71/800, Train Loss: 0.0292, Val Loss: 0.5613, Val Accuracy: 84.11%\n",
      "Epoch 72/800, Train Loss: 0.0081, Val Loss: 0.6667, Val Accuracy: 80.37%\n",
      "Epoch 73/800, Train Loss: 0.0140, Val Loss: 0.9274, Val Accuracy: 76.64%\n",
      "Epoch 74/800, Train Loss: 0.0038, Val Loss: 0.5867, Val Accuracy: 84.11%\n",
      "Epoch 75/800, Train Loss: 0.0033, Val Loss: 0.5549, Val Accuracy: 83.18%\n",
      "Epoch 76/800, Train Loss: 0.0016, Val Loss: 0.5797, Val Accuracy: 84.11%\n",
      "Epoch 77/800, Train Loss: 0.0020, Val Loss: 0.6279, Val Accuracy: 85.05%\n",
      "Epoch 78/800, Train Loss: 0.0012, Val Loss: 0.6471, Val Accuracy: 84.11%\n",
      "Epoch 79/800, Train Loss: 0.0038, Val Loss: 0.6159, Val Accuracy: 85.05%\n",
      "Epoch 80/800, Train Loss: 0.0015, Val Loss: 0.6759, Val Accuracy: 83.18%\n",
      "Epoch 81/800, Train Loss: 0.0014, Val Loss: 0.6769, Val Accuracy: 84.11%\n",
      "Epoch 82/800, Train Loss: 0.0008, Val Loss: 0.6317, Val Accuracy: 85.98%\n",
      "Epoch 83/800, Train Loss: 0.0008, Val Loss: 0.6115, Val Accuracy: 85.05%\n",
      "Epoch 84/800, Train Loss: 0.0019, Val Loss: 0.6069, Val Accuracy: 85.05%\n",
      "Epoch 85/800, Train Loss: 0.0024, Val Loss: 0.6678, Val Accuracy: 79.44%\n",
      "Epoch 86/800, Train Loss: 0.0044, Val Loss: 0.5743, Val Accuracy: 82.24%\n",
      "Epoch 87/800, Train Loss: 0.0033, Val Loss: 0.5477, Val Accuracy: 85.98%\n",
      "Epoch 88/800, Train Loss: 0.0093, Val Loss: 0.5085, Val Accuracy: 80.37%\n",
      "Epoch 89/800, Train Loss: 0.0027, Val Loss: 0.5381, Val Accuracy: 86.92%\n",
      "Epoch 90/800, Train Loss: 0.0016, Val Loss: 0.5706, Val Accuracy: 87.85%\n",
      "Epoch 91/800, Train Loss: 0.0028, Val Loss: 0.5879, Val Accuracy: 85.05%\n",
      "Epoch 92/800, Train Loss: 0.0013, Val Loss: 0.5877, Val Accuracy: 85.05%\n",
      "Epoch 93/800, Train Loss: 0.0009, Val Loss: 0.5637, Val Accuracy: 84.11%\n",
      "Epoch 94/800, Train Loss: 0.0011, Val Loss: 0.5433, Val Accuracy: 85.05%\n",
      "Epoch 95/800, Train Loss: 0.0015, Val Loss: 0.5719, Val Accuracy: 84.11%\n",
      "Epoch 96/800, Train Loss: 0.0010, Val Loss: 0.5425, Val Accuracy: 84.11%\n",
      "Epoch 97/800, Train Loss: 0.0007, Val Loss: 0.5446, Val Accuracy: 85.05%\n",
      "Epoch 98/800, Train Loss: 0.0011, Val Loss: 0.5150, Val Accuracy: 85.05%\n",
      "Epoch 99/800, Train Loss: 0.0008, Val Loss: 0.5365, Val Accuracy: 84.11%\n",
      "Epoch 100/800, Train Loss: 0.0014, Val Loss: 0.5541, Val Accuracy: 84.11%\n",
      "Epoch 101/800, Train Loss: 0.0006, Val Loss: 0.5182, Val Accuracy: 82.24%\n",
      "Epoch 102/800, Train Loss: 0.0006, Val Loss: 0.5261, Val Accuracy: 83.18%\n",
      "Epoch 103/800, Train Loss: 0.0006, Val Loss: 0.5366, Val Accuracy: 85.05%\n",
      "Epoch 104/800, Train Loss: 0.0004, Val Loss: 0.5134, Val Accuracy: 83.18%\n",
      "Epoch 105/800, Train Loss: 0.0009, Val Loss: 0.5324, Val Accuracy: 84.11%\n",
      "Epoch 106/800, Train Loss: 0.0006, Val Loss: 0.6137, Val Accuracy: 84.11%\n",
      "Epoch 107/800, Train Loss: 0.0010, Val Loss: 0.6089, Val Accuracy: 84.11%\n",
      "Epoch 108/800, Train Loss: 0.0004, Val Loss: 0.6016, Val Accuracy: 85.98%\n",
      "Epoch 109/800, Train Loss: 0.0004, Val Loss: 0.5688, Val Accuracy: 85.05%\n",
      "Epoch 110/800, Train Loss: 0.0005, Val Loss: 0.5741, Val Accuracy: 83.18%\n",
      "Epoch 111/800, Train Loss: 0.0010, Val Loss: 0.5794, Val Accuracy: 85.05%\n",
      "Epoch 112/800, Train Loss: 0.0005, Val Loss: 0.5802, Val Accuracy: 84.11%\n",
      "Epoch 113/800, Train Loss: 0.0006, Val Loss: 0.5888, Val Accuracy: 83.18%\n",
      "Epoch 114/800, Train Loss: 0.0006, Val Loss: 0.5559, Val Accuracy: 83.18%\n",
      "Epoch 115/800, Train Loss: 0.0005, Val Loss: 0.5677, Val Accuracy: 84.11%\n",
      "Epoch 116/800, Train Loss: 0.0005, Val Loss: 0.5568, Val Accuracy: 84.11%\n",
      "Epoch 117/800, Train Loss: 0.0004, Val Loss: 0.5667, Val Accuracy: 84.11%\n",
      "Epoch 118/800, Train Loss: 0.0003, Val Loss: 0.5453, Val Accuracy: 84.11%\n",
      "Epoch 119/800, Train Loss: 0.0005, Val Loss: 0.5543, Val Accuracy: 85.05%\n",
      "Epoch 120/800, Train Loss: 0.0004, Val Loss: 0.5500, Val Accuracy: 84.11%\n",
      "Epoch 121/800, Train Loss: 0.0004, Val Loss: 0.5386, Val Accuracy: 84.11%\n",
      "Epoch 122/800, Train Loss: 0.0014, Val Loss: 0.5519, Val Accuracy: 84.11%\n",
      "Epoch 123/800, Train Loss: 0.0028, Val Loss: 0.6447, Val Accuracy: 80.37%\n",
      "Epoch 124/800, Train Loss: 0.0033, Val Loss: 0.6484, Val Accuracy: 78.50%\n",
      "Epoch 125/800, Train Loss: 0.0648, Val Loss: 1.0587, Val Accuracy: 71.96%\n",
      "Epoch 126/800, Train Loss: 0.0333, Val Loss: 1.9771, Val Accuracy: 68.22%\n",
      "Epoch 127/800, Train Loss: 0.0276, Val Loss: 0.7805, Val Accuracy: 77.57%\n",
      "Epoch 128/800, Train Loss: 0.0054, Val Loss: 0.9387, Val Accuracy: 74.77%\n",
      "Epoch 129/800, Train Loss: 0.0079, Val Loss: 0.6746, Val Accuracy: 84.11%\n",
      "Epoch 130/800, Train Loss: 0.0037, Val Loss: 0.6835, Val Accuracy: 81.31%\n",
      "Epoch 131/800, Train Loss: 0.0041, Val Loss: 0.5851, Val Accuracy: 80.37%\n",
      "Epoch 132/800, Train Loss: 0.0118, Val Loss: 1.0274, Val Accuracy: 74.77%\n",
      "Epoch 133/800, Train Loss: 0.0264, Val Loss: 1.5994, Val Accuracy: 60.75%\n",
      "Epoch 134/800, Train Loss: 0.0642, Val Loss: 1.0334, Val Accuracy: 65.42%\n",
      "Epoch 135/800, Train Loss: 0.0392, Val Loss: 1.1783, Val Accuracy: 71.03%\n",
      "Epoch 136/800, Train Loss: 0.0266, Val Loss: 1.1244, Val Accuracy: 78.50%\n",
      "Epoch 137/800, Train Loss: 0.0405, Val Loss: 1.6257, Val Accuracy: 63.55%\n",
      "Epoch 138/800, Train Loss: 0.0347, Val Loss: 1.7088, Val Accuracy: 66.36%\n",
      "Epoch 139/800, Train Loss: 0.0693, Val Loss: 1.0930, Val Accuracy: 77.57%\n",
      "Epoch 140/800, Train Loss: 0.0961, Val Loss: 1.1656, Val Accuracy: 68.22%\n",
      "Epoch 141/800, Train Loss: 0.0321, Val Loss: 2.5321, Val Accuracy: 60.75%\n",
      "Epoch 142/800, Train Loss: 0.0203, Val Loss: 1.1551, Val Accuracy: 70.09%\n",
      "Epoch 143/800, Train Loss: 0.0679, Val Loss: 1.9042, Val Accuracy: 57.01%\n",
      "Epoch 144/800, Train Loss: 0.1158, Val Loss: 1.4827, Val Accuracy: 57.01%\n",
      "Epoch 145/800, Train Loss: 0.1100, Val Loss: 1.1581, Val Accuracy: 69.16%\n",
      "Epoch 146/800, Train Loss: 0.0659, Val Loss: 1.7014, Val Accuracy: 70.09%\n",
      "Epoch 147/800, Train Loss: 0.0147, Val Loss: 1.0617, Val Accuracy: 73.83%\n",
      "Epoch 148/800, Train Loss: 0.0191, Val Loss: 0.9057, Val Accuracy: 73.83%\n",
      "Epoch 149/800, Train Loss: 0.0113, Val Loss: 0.7326, Val Accuracy: 76.64%\n",
      "Epoch 150/800, Train Loss: 0.0143, Val Loss: 0.9272, Val Accuracy: 72.90%\n",
      "Epoch 151/800, Train Loss: 0.0036, Val Loss: 0.9179, Val Accuracy: 77.57%\n",
      "Epoch 152/800, Train Loss: 0.0022, Val Loss: 0.8334, Val Accuracy: 78.50%\n",
      "Epoch 153/800, Train Loss: 0.0016, Val Loss: 0.8190, Val Accuracy: 77.57%\n",
      "Epoch 154/800, Train Loss: 0.0011, Val Loss: 0.8332, Val Accuracy: 78.50%\n",
      "Epoch 155/800, Train Loss: 0.0012, Val Loss: 0.8239, Val Accuracy: 78.50%\n",
      "Epoch 156/800, Train Loss: 0.0012, Val Loss: 0.7748, Val Accuracy: 79.44%\n",
      "Epoch 157/800, Train Loss: 0.0011, Val Loss: 0.8025, Val Accuracy: 79.44%\n",
      "Epoch 158/800, Train Loss: 0.0007, Val Loss: 0.7875, Val Accuracy: 79.44%\n",
      "Epoch 159/800, Train Loss: 0.0007, Val Loss: 0.7788, Val Accuracy: 78.50%\n",
      "Epoch 160/800, Train Loss: 0.0015, Val Loss: 0.7788, Val Accuracy: 79.44%\n",
      "Epoch 161/800, Train Loss: 0.0008, Val Loss: 0.7604, Val Accuracy: 79.44%\n",
      "Epoch 162/800, Train Loss: 0.0006, Val Loss: 0.7462, Val Accuracy: 80.37%\n",
      "Epoch 163/800, Train Loss: 0.0007, Val Loss: 0.8252, Val Accuracy: 78.50%\n",
      "Epoch 164/800, Train Loss: 0.0010, Val Loss: 0.8126, Val Accuracy: 77.57%\n",
      "Epoch 165/800, Train Loss: 0.0007, Val Loss: 0.8031, Val Accuracy: 78.50%\n",
      "Epoch 166/800, Train Loss: 0.0003, Val Loss: 0.7561, Val Accuracy: 78.50%\n",
      "Epoch 167/800, Train Loss: 0.0008, Val Loss: 0.7695, Val Accuracy: 78.50%\n",
      "Epoch 168/800, Train Loss: 0.0006, Val Loss: 0.7177, Val Accuracy: 79.44%\n",
      "Epoch 169/800, Train Loss: 0.0005, Val Loss: 0.7263, Val Accuracy: 79.44%\n",
      "Epoch 170/800, Train Loss: 0.0004, Val Loss: 0.6993, Val Accuracy: 79.44%\n",
      "Epoch 171/800, Train Loss: 0.0007, Val Loss: 0.7237, Val Accuracy: 78.50%\n",
      "Epoch 172/800, Train Loss: 0.0006, Val Loss: 0.6784, Val Accuracy: 79.44%\n",
      "Epoch 173/800, Train Loss: 0.0004, Val Loss: 0.7265, Val Accuracy: 79.44%\n",
      "Epoch 174/800, Train Loss: 0.0012, Val Loss: 0.7202, Val Accuracy: 79.44%\n",
      "Epoch 175/800, Train Loss: 0.0004, Val Loss: 0.7124, Val Accuracy: 79.44%\n",
      "Epoch 176/800, Train Loss: 0.0006, Val Loss: 0.7111, Val Accuracy: 79.44%\n",
      "Epoch 177/800, Train Loss: 0.0003, Val Loss: 0.7238, Val Accuracy: 79.44%\n",
      "Epoch 178/800, Train Loss: 0.0003, Val Loss: 0.7294, Val Accuracy: 79.44%\n",
      "Epoch 179/800, Train Loss: 0.0006, Val Loss: 0.7230, Val Accuracy: 78.50%\n",
      "Epoch 180/800, Train Loss: 0.0003, Val Loss: 0.7832, Val Accuracy: 78.50%\n",
      "Epoch 181/800, Train Loss: 0.0004, Val Loss: 0.7819, Val Accuracy: 78.50%\n",
      "Epoch 182/800, Train Loss: 0.0009, Val Loss: 0.7395, Val Accuracy: 80.37%\n",
      "Epoch 183/800, Train Loss: 0.0003, Val Loss: 0.7246, Val Accuracy: 79.44%\n",
      "Epoch 184/800, Train Loss: 0.0002, Val Loss: 0.7787, Val Accuracy: 78.50%\n",
      "Epoch 185/800, Train Loss: 0.0004, Val Loss: 0.7536, Val Accuracy: 78.50%\n",
      "Epoch 186/800, Train Loss: 0.0009, Val Loss: 0.7030, Val Accuracy: 79.44%\n",
      "Epoch 187/800, Train Loss: 0.0003, Val Loss: 0.7257, Val Accuracy: 80.37%\n",
      "Epoch 188/800, Train Loss: 0.0003, Val Loss: 0.7102, Val Accuracy: 81.31%\n",
      "Epoch 189/800, Train Loss: 0.0004, Val Loss: 0.7367, Val Accuracy: 79.44%\n",
      "Epoch 190/800, Train Loss: 0.0006, Val Loss: 0.7403, Val Accuracy: 81.31%\n",
      "Epoch 191/800, Train Loss: 0.0002, Val Loss: 0.7446, Val Accuracy: 81.31%\n",
      "Epoch 192/800, Train Loss: 0.0002, Val Loss: 0.7204, Val Accuracy: 80.37%\n",
      "Epoch 193/800, Train Loss: 0.0003, Val Loss: 0.7349, Val Accuracy: 80.37%\n",
      "Epoch 194/800, Train Loss: 0.0002, Val Loss: 0.7767, Val Accuracy: 81.31%\n",
      "Epoch 195/800, Train Loss: 0.0003, Val Loss: 0.7897, Val Accuracy: 79.44%\n",
      "Epoch 196/800, Train Loss: 0.0003, Val Loss: 0.7752, Val Accuracy: 78.50%\n",
      "Epoch 197/800, Train Loss: 0.0002, Val Loss: 0.7723, Val Accuracy: 80.37%\n",
      "Epoch 198/800, Train Loss: 0.0002, Val Loss: 0.7766, Val Accuracy: 78.50%\n",
      "Epoch 199/800, Train Loss: 0.0003, Val Loss: 0.7734, Val Accuracy: 79.44%\n",
      "Epoch 200/800, Train Loss: 0.0003, Val Loss: 0.7450, Val Accuracy: 78.50%\n",
      "Epoch 201/800, Train Loss: 0.0002, Val Loss: 0.7316, Val Accuracy: 80.37%\n",
      "Epoch 202/800, Train Loss: 0.0002, Val Loss: 0.7467, Val Accuracy: 80.37%\n",
      "Epoch 203/800, Train Loss: 0.0001, Val Loss: 0.7620, Val Accuracy: 80.37%\n",
      "Epoch 204/800, Train Loss: 0.0001, Val Loss: 0.7658, Val Accuracy: 80.37%\n",
      "Epoch 205/800, Train Loss: 0.0003, Val Loss: 0.7796, Val Accuracy: 80.37%\n",
      "Epoch 206/800, Train Loss: 0.0002, Val Loss: 0.7953, Val Accuracy: 78.50%\n",
      "Epoch 207/800, Train Loss: 0.0002, Val Loss: 0.7709, Val Accuracy: 79.44%\n",
      "Epoch 208/800, Train Loss: 0.0003, Val Loss: 0.7896, Val Accuracy: 80.37%\n",
      "Epoch 209/800, Train Loss: 0.0004, Val Loss: 0.7899, Val Accuracy: 81.31%\n",
      "Epoch 210/800, Train Loss: 0.0002, Val Loss: 0.7526, Val Accuracy: 80.37%\n",
      "Epoch 211/800, Train Loss: 0.0003, Val Loss: 0.7528, Val Accuracy: 80.37%\n",
      "Epoch 212/800, Train Loss: 0.0003, Val Loss: 0.8707, Val Accuracy: 78.50%\n",
      "Epoch 213/800, Train Loss: 0.0003, Val Loss: 0.7487, Val Accuracy: 80.37%\n",
      "Epoch 214/800, Train Loss: 0.0002, Val Loss: 0.7586, Val Accuracy: 81.31%\n",
      "Epoch 215/800, Train Loss: 0.0002, Val Loss: 0.7577, Val Accuracy: 81.31%\n",
      "Epoch 216/800, Train Loss: 0.0002, Val Loss: 0.7738, Val Accuracy: 78.50%\n",
      "Epoch 217/800, Train Loss: 0.0002, Val Loss: 0.7913, Val Accuracy: 78.50%\n",
      "Epoch 218/800, Train Loss: 0.0002, Val Loss: 0.7636, Val Accuracy: 81.31%\n",
      "Epoch 219/800, Train Loss: 0.0002, Val Loss: 0.8406, Val Accuracy: 78.50%\n",
      "Epoch 220/800, Train Loss: 0.0003, Val Loss: 0.8079, Val Accuracy: 79.44%\n",
      "Epoch 221/800, Train Loss: 0.0002, Val Loss: 0.7728, Val Accuracy: 80.37%\n",
      "Epoch 222/800, Train Loss: 0.0002, Val Loss: 0.7817, Val Accuracy: 80.37%\n",
      "Epoch 223/800, Train Loss: 0.0001, Val Loss: 0.7533, Val Accuracy: 80.37%\n",
      "Epoch 224/800, Train Loss: 0.0001, Val Loss: 0.7554, Val Accuracy: 81.31%\n",
      "Epoch 225/800, Train Loss: 0.0001, Val Loss: 0.7665, Val Accuracy: 80.37%\n",
      "Epoch 226/800, Train Loss: 0.0002, Val Loss: 0.8173, Val Accuracy: 78.50%\n",
      "Epoch 227/800, Train Loss: 0.0002, Val Loss: 0.7862, Val Accuracy: 80.37%\n",
      "Epoch 228/800, Train Loss: 0.0003, Val Loss: 0.7686, Val Accuracy: 80.37%\n",
      "Epoch 229/800, Train Loss: 0.0002, Val Loss: 0.7915, Val Accuracy: 79.44%\n",
      "Epoch 230/800, Train Loss: 0.0002, Val Loss: 0.7658, Val Accuracy: 79.44%\n",
      "Epoch 231/800, Train Loss: 0.0009, Val Loss: 0.7824, Val Accuracy: 80.37%\n",
      "Epoch 232/800, Train Loss: 0.0040, Val Loss: 0.7661, Val Accuracy: 81.31%\n",
      "Epoch 233/800, Train Loss: 0.0088, Val Loss: 0.8630, Val Accuracy: 78.50%\n",
      "Epoch 234/800, Train Loss: 0.0062, Val Loss: 0.8304, Val Accuracy: 75.70%\n",
      "Epoch 235/800, Train Loss: 0.0057, Val Loss: 0.7024, Val Accuracy: 79.44%\n",
      "Epoch 236/800, Train Loss: 0.0036, Val Loss: 0.8507, Val Accuracy: 77.57%\n",
      "Epoch 237/800, Train Loss: 0.0041, Val Loss: 0.7145, Val Accuracy: 81.31%\n",
      "Epoch 238/800, Train Loss: 0.0145, Val Loss: 0.8226, Val Accuracy: 71.03%\n",
      "Epoch 239/800, Train Loss: 0.0206, Val Loss: 2.3845, Val Accuracy: 54.21%\n",
      "Epoch 240/800, Train Loss: 0.0084, Val Loss: 0.7886, Val Accuracy: 76.64%\n",
      "Epoch 241/800, Train Loss: 0.0057, Val Loss: 0.7513, Val Accuracy: 78.50%\n",
      "Epoch 242/800, Train Loss: 0.0066, Val Loss: 0.8062, Val Accuracy: 77.57%\n",
      "Epoch 243/800, Train Loss: 0.0076, Val Loss: 0.8246, Val Accuracy: 76.64%\n",
      "Epoch 244/800, Train Loss: 0.0046, Val Loss: 0.9522, Val Accuracy: 76.64%\n",
      "Epoch 245/800, Train Loss: 0.0012, Val Loss: 0.5968, Val Accuracy: 84.11%\n",
      "Epoch 246/800, Train Loss: 0.0012, Val Loss: 0.6198, Val Accuracy: 86.92%\n",
      "Epoch 247/800, Train Loss: 0.0005, Val Loss: 0.6108, Val Accuracy: 86.92%\n",
      "Epoch 248/800, Train Loss: 0.0015, Val Loss: 0.6076, Val Accuracy: 85.98%\n",
      "Epoch 249/800, Train Loss: 0.0018, Val Loss: 0.6553, Val Accuracy: 85.98%\n",
      "Epoch 250/800, Train Loss: 0.0007, Val Loss: 0.6176, Val Accuracy: 85.98%\n",
      "Epoch 251/800, Train Loss: 0.0030, Val Loss: 0.6047, Val Accuracy: 84.11%\n",
      "Epoch 252/800, Train Loss: 0.0426, Val Loss: 1.3388, Val Accuracy: 64.49%\n",
      "Epoch 253/800, Train Loss: 0.0143, Val Loss: 0.7672, Val Accuracy: 79.44%\n",
      "Epoch 254/800, Train Loss: 0.0208, Val Loss: 0.9440, Val Accuracy: 70.09%\n",
      "Epoch 255/800, Train Loss: 0.0193, Val Loss: 1.3058, Val Accuracy: 69.16%\n",
      "Epoch 256/800, Train Loss: 0.0046, Val Loss: 0.7913, Val Accuracy: 80.37%\n",
      "Epoch 257/800, Train Loss: 0.0018, Val Loss: 0.7697, Val Accuracy: 80.37%\n",
      "Epoch 258/800, Train Loss: 0.0021, Val Loss: 0.7876, Val Accuracy: 79.44%\n",
      "Epoch 259/800, Train Loss: 0.0010, Val Loss: 0.7075, Val Accuracy: 80.37%\n",
      "Epoch 260/800, Train Loss: 0.0019, Val Loss: 0.7579, Val Accuracy: 84.11%\n",
      "Epoch 261/800, Train Loss: 0.0342, Val Loss: 1.1739, Val Accuracy: 70.09%\n",
      "Epoch 262/800, Train Loss: 0.1731, Val Loss: 2.5395, Val Accuracy: 57.01%\n",
      "Epoch 263/800, Train Loss: 0.4080, Val Loss: 2.7149, Val Accuracy: 63.55%\n",
      "Epoch 264/800, Train Loss: 0.2370, Val Loss: 3.3164, Val Accuracy: 41.12%\n",
      "Epoch 265/800, Train Loss: 0.0902, Val Loss: 1.5503, Val Accuracy: 62.62%\n",
      "Epoch 266/800, Train Loss: 0.0366, Val Loss: 0.7933, Val Accuracy: 72.90%\n",
      "Epoch 267/800, Train Loss: 0.0154, Val Loss: 0.5619, Val Accuracy: 81.31%\n",
      "Epoch 268/800, Train Loss: 0.0202, Val Loss: 0.5898, Val Accuracy: 81.31%\n",
      "Epoch 269/800, Train Loss: 0.0329, Val Loss: 0.7340, Val Accuracy: 78.50%\n",
      "Epoch 270/800, Train Loss: 0.0173, Val Loss: 0.8428, Val Accuracy: 79.44%\n",
      "Epoch 271/800, Train Loss: 0.0070, Val Loss: 0.7267, Val Accuracy: 81.31%\n",
      "Epoch 272/800, Train Loss: 0.0035, Val Loss: 0.7384, Val Accuracy: 80.37%\n",
      "Epoch 273/800, Train Loss: 0.0072, Val Loss: 0.8097, Val Accuracy: 77.57%\n",
      "Epoch 274/800, Train Loss: 0.0202, Val Loss: 1.0310, Val Accuracy: 73.83%\n",
      "Epoch 275/800, Train Loss: 0.0122, Val Loss: 1.1821, Val Accuracy: 69.16%\n",
      "Epoch 276/800, Train Loss: 0.0182, Val Loss: 1.2267, Val Accuracy: 71.03%\n",
      "Epoch 277/800, Train Loss: 0.0058, Val Loss: 0.7842, Val Accuracy: 77.57%\n",
      "Epoch 278/800, Train Loss: 0.0033, Val Loss: 0.5965, Val Accuracy: 81.31%\n",
      "Epoch 279/800, Train Loss: 0.0020, Val Loss: 0.6020, Val Accuracy: 82.24%\n",
      "Epoch 280/800, Train Loss: 0.0011, Val Loss: 0.6242, Val Accuracy: 82.24%\n",
      "Epoch 281/800, Train Loss: 0.0016, Val Loss: 0.6621, Val Accuracy: 80.37%\n",
      "Epoch 282/800, Train Loss: 0.0012, Val Loss: 0.7027, Val Accuracy: 79.44%\n",
      "Epoch 283/800, Train Loss: 0.0010, Val Loss: 0.7424, Val Accuracy: 79.44%\n",
      "Epoch 284/800, Train Loss: 0.0009, Val Loss: 0.7220, Val Accuracy: 79.44%\n",
      "Epoch 285/800, Train Loss: 0.0008, Val Loss: 0.7104, Val Accuracy: 78.50%\n",
      "Epoch 286/800, Train Loss: 0.0009, Val Loss: 0.6842, Val Accuracy: 81.31%\n",
      "Epoch 287/800, Train Loss: 0.0008, Val Loss: 0.6700, Val Accuracy: 82.24%\n",
      "Epoch 288/800, Train Loss: 0.0008, Val Loss: 0.6898, Val Accuracy: 81.31%\n",
      "Epoch 289/800, Train Loss: 0.0014, Val Loss: 0.6780, Val Accuracy: 79.44%\n",
      "Epoch 290/800, Train Loss: 0.0021, Val Loss: 0.6573, Val Accuracy: 77.57%\n",
      "Epoch 291/800, Train Loss: 0.0009, Val Loss: 0.6212, Val Accuracy: 81.31%\n",
      "Epoch 292/800, Train Loss: 0.0005, Val Loss: 0.6541, Val Accuracy: 80.37%\n",
      "Epoch 293/800, Train Loss: 0.0016, Val Loss: 0.7451, Val Accuracy: 80.37%\n",
      "Epoch 294/800, Train Loss: 0.0005, Val Loss: 0.7384, Val Accuracy: 81.31%\n",
      "Epoch 295/800, Train Loss: 0.0007, Val Loss: 0.7103, Val Accuracy: 79.44%\n",
      "Epoch 296/800, Train Loss: 0.0005, Val Loss: 0.7117, Val Accuracy: 81.31%\n",
      "Epoch 297/800, Train Loss: 0.0009, Val Loss: 0.7286, Val Accuracy: 79.44%\n",
      "Epoch 298/800, Train Loss: 0.0004, Val Loss: 0.6910, Val Accuracy: 81.31%\n",
      "Epoch 299/800, Train Loss: 0.0004, Val Loss: 0.6773, Val Accuracy: 82.24%\n",
      "Epoch 300/800, Train Loss: 0.0005, Val Loss: 0.6537, Val Accuracy: 82.24%\n",
      "Epoch 301/800, Train Loss: 0.0003, Val Loss: 0.6394, Val Accuracy: 81.31%\n",
      "Epoch 302/800, Train Loss: 0.0002, Val Loss: 0.6531, Val Accuracy: 82.24%\n",
      "Epoch 303/800, Train Loss: 0.0002, Val Loss: 0.6713, Val Accuracy: 82.24%\n",
      "Epoch 304/800, Train Loss: 0.0004, Val Loss: 0.6614, Val Accuracy: 81.31%\n",
      "Epoch 305/800, Train Loss: 0.0003, Val Loss: 0.6541, Val Accuracy: 81.31%\n",
      "Epoch 306/800, Train Loss: 0.0002, Val Loss: 0.6575, Val Accuracy: 82.24%\n",
      "Epoch 307/800, Train Loss: 0.0004, Val Loss: 0.6766, Val Accuracy: 81.31%\n",
      "Epoch 308/800, Train Loss: 0.0003, Val Loss: 0.6582, Val Accuracy: 80.37%\n",
      "Epoch 309/800, Train Loss: 0.0003, Val Loss: 0.6741, Val Accuracy: 81.31%\n",
      "Epoch 310/800, Train Loss: 0.0007, Val Loss: 0.6684, Val Accuracy: 81.31%\n",
      "Epoch 311/800, Train Loss: 0.0026, Val Loss: 0.7414, Val Accuracy: 78.50%\n",
      "Epoch 312/800, Train Loss: 0.0213, Val Loss: 1.2775, Val Accuracy: 70.09%\n",
      "Epoch 313/800, Train Loss: 0.0356, Val Loss: 1.5215, Val Accuracy: 65.42%\n",
      "Epoch 314/800, Train Loss: 0.0319, Val Loss: 0.8428, Val Accuracy: 78.50%\n",
      "Epoch 315/800, Train Loss: 0.0110, Val Loss: 0.7676, Val Accuracy: 85.98%\n",
      "Epoch 316/800, Train Loss: 0.0066, Val Loss: 0.6642, Val Accuracy: 81.31%\n",
      "Epoch 317/800, Train Loss: 0.0023, Val Loss: 0.7087, Val Accuracy: 78.50%\n",
      "Epoch 318/800, Train Loss: 0.0055, Val Loss: 0.7079, Val Accuracy: 81.31%\n",
      "Epoch 319/800, Train Loss: 0.0147, Val Loss: 0.7095, Val Accuracy: 79.44%\n",
      "Epoch 320/800, Train Loss: 0.0084, Val Loss: 0.7518, Val Accuracy: 77.57%\n",
      "Epoch 321/800, Train Loss: 0.0033, Val Loss: 0.6939, Val Accuracy: 79.44%\n",
      "Epoch 322/800, Train Loss: 0.0029, Val Loss: 0.6651, Val Accuracy: 83.18%\n",
      "Epoch 323/800, Train Loss: 0.0062, Val Loss: 0.6926, Val Accuracy: 83.18%\n",
      "Epoch 324/800, Train Loss: 0.0060, Val Loss: 0.7416, Val Accuracy: 82.24%\n",
      "Epoch 325/800, Train Loss: 0.0089, Val Loss: 1.6279, Val Accuracy: 75.70%\n",
      "Epoch 326/800, Train Loss: 0.0121, Val Loss: 0.9002, Val Accuracy: 72.90%\n",
      "Epoch 327/800, Train Loss: 0.0180, Val Loss: 0.8696, Val Accuracy: 77.57%\n",
      "Epoch 328/800, Train Loss: 0.0103, Val Loss: 0.6707, Val Accuracy: 82.24%\n",
      "Epoch 329/800, Train Loss: 0.0168, Val Loss: 0.6937, Val Accuracy: 77.57%\n",
      "Epoch 330/800, Train Loss: 0.0551, Val Loss: 0.9090, Val Accuracy: 74.77%\n",
      "Epoch 331/800, Train Loss: 0.0132, Val Loss: 1.5465, Val Accuracy: 66.36%\n",
      "Epoch 332/800, Train Loss: 0.0115, Val Loss: 0.8263, Val Accuracy: 77.57%\n",
      "Epoch 333/800, Train Loss: 0.0054, Val Loss: 0.7934, Val Accuracy: 80.37%\n",
      "Epoch 334/800, Train Loss: 0.0026, Val Loss: 0.9560, Val Accuracy: 75.70%\n",
      "Epoch 335/800, Train Loss: 0.0117, Val Loss: 0.6923, Val Accuracy: 76.64%\n",
      "Epoch 336/800, Train Loss: 0.0020, Val Loss: 0.7144, Val Accuracy: 78.50%\n",
      "Epoch 337/800, Train Loss: 0.0052, Val Loss: 0.7666, Val Accuracy: 74.77%\n",
      "Epoch 338/800, Train Loss: 0.0018, Val Loss: 0.7384, Val Accuracy: 74.77%\n",
      "Epoch 339/800, Train Loss: 0.0011, Val Loss: 0.7418, Val Accuracy: 76.64%\n",
      "Epoch 340/800, Train Loss: 0.0007, Val Loss: 0.7118, Val Accuracy: 79.44%\n",
      "Epoch 341/800, Train Loss: 0.0008, Val Loss: 0.7405, Val Accuracy: 77.57%\n",
      "Epoch 342/800, Train Loss: 0.0005, Val Loss: 0.7116, Val Accuracy: 77.57%\n",
      "Epoch 343/800, Train Loss: 0.0018, Val Loss: 0.7732, Val Accuracy: 77.57%\n",
      "Epoch 344/800, Train Loss: 0.0048, Val Loss: 0.8610, Val Accuracy: 78.50%\n",
      "Epoch 345/800, Train Loss: 0.0008, Val Loss: 0.8382, Val Accuracy: 78.50%\n",
      "Epoch 346/800, Train Loss: 0.0010, Val Loss: 0.8380, Val Accuracy: 77.57%\n",
      "Epoch 347/800, Train Loss: 0.0018, Val Loss: 0.7623, Val Accuracy: 80.37%\n",
      "Epoch 348/800, Train Loss: 0.0011, Val Loss: 0.7094, Val Accuracy: 78.50%\n",
      "Epoch 349/800, Train Loss: 0.0006, Val Loss: 0.7112, Val Accuracy: 79.44%\n",
      "Epoch 350/800, Train Loss: 0.0004, Val Loss: 0.6899, Val Accuracy: 81.31%\n",
      "Epoch 351/800, Train Loss: 0.0003, Val Loss: 0.6770, Val Accuracy: 79.44%\n",
      "Epoch 352/800, Train Loss: 0.0005, Val Loss: 0.6843, Val Accuracy: 80.37%\n",
      "Epoch 353/800, Train Loss: 0.0007, Val Loss: 0.7417, Val Accuracy: 80.37%\n",
      "Epoch 354/800, Train Loss: 0.0004, Val Loss: 0.6747, Val Accuracy: 81.31%\n",
      "Epoch 355/800, Train Loss: 0.0002, Val Loss: 0.6455, Val Accuracy: 84.11%\n",
      "Epoch 356/800, Train Loss: 0.0003, Val Loss: 0.6443, Val Accuracy: 84.11%\n",
      "Epoch 357/800, Train Loss: 0.0003, Val Loss: 0.6467, Val Accuracy: 84.11%\n",
      "Epoch 358/800, Train Loss: 0.0004, Val Loss: 0.6748, Val Accuracy: 82.24%\n",
      "Epoch 359/800, Train Loss: 0.0004, Val Loss: 0.6581, Val Accuracy: 83.18%\n",
      "Epoch 360/800, Train Loss: 0.0002, Val Loss: 0.7205, Val Accuracy: 81.31%\n",
      "Epoch 361/800, Train Loss: 0.0002, Val Loss: 0.6846, Val Accuracy: 83.18%\n",
      "Epoch 362/800, Train Loss: 0.0004, Val Loss: 0.6804, Val Accuracy: 81.31%\n",
      "Epoch 363/800, Train Loss: 0.0003, Val Loss: 0.7046, Val Accuracy: 82.24%\n",
      "Epoch 364/800, Train Loss: 0.0002, Val Loss: 0.6770, Val Accuracy: 83.18%\n",
      "Epoch 365/800, Train Loss: 0.0003, Val Loss: 0.6885, Val Accuracy: 80.37%\n",
      "Epoch 366/800, Train Loss: 0.0002, Val Loss: 0.6894, Val Accuracy: 82.24%\n",
      "Epoch 367/800, Train Loss: 0.0002, Val Loss: 0.6905, Val Accuracy: 81.31%\n",
      "Epoch 368/800, Train Loss: 0.0002, Val Loss: 0.6931, Val Accuracy: 80.37%\n",
      "Epoch 369/800, Train Loss: 0.0003, Val Loss: 0.6934, Val Accuracy: 82.24%\n",
      "Epoch 370/800, Train Loss: 0.0001, Val Loss: 0.7065, Val Accuracy: 80.37%\n",
      "Epoch 371/800, Train Loss: 0.0003, Val Loss: 0.7155, Val Accuracy: 80.37%\n",
      "Epoch 372/800, Train Loss: 0.0002, Val Loss: 0.6551, Val Accuracy: 79.44%\n",
      "Epoch 373/800, Train Loss: 0.0002, Val Loss: 0.6592, Val Accuracy: 80.37%\n",
      "Epoch 374/800, Train Loss: 0.0002, Val Loss: 0.6644, Val Accuracy: 79.44%\n",
      "Epoch 375/800, Train Loss: 0.0006, Val Loss: 0.6642, Val Accuracy: 81.31%\n",
      "Epoch 376/800, Train Loss: 0.0007, Val Loss: 0.6452, Val Accuracy: 83.18%\n",
      "Epoch 377/800, Train Loss: 0.0002, Val Loss: 0.6720, Val Accuracy: 81.31%\n",
      "Epoch 378/800, Train Loss: 0.0002, Val Loss: 0.6607, Val Accuracy: 82.24%\n",
      "Epoch 379/800, Train Loss: 0.0002, Val Loss: 0.6912, Val Accuracy: 82.24%\n",
      "Epoch 380/800, Train Loss: 0.0001, Val Loss: 0.6801, Val Accuracy: 82.24%\n",
      "Epoch 381/800, Train Loss: 0.0009, Val Loss: 0.6891, Val Accuracy: 82.24%\n",
      "Epoch 382/800, Train Loss: 0.0003, Val Loss: 0.7406, Val Accuracy: 82.24%\n",
      "Epoch 383/800, Train Loss: 0.0004, Val Loss: 0.6683, Val Accuracy: 80.37%\n",
      "Epoch 384/800, Train Loss: 0.0002, Val Loss: 0.7310, Val Accuracy: 82.24%\n",
      "Epoch 385/800, Train Loss: 0.0002, Val Loss: 0.7553, Val Accuracy: 81.31%\n",
      "Epoch 386/800, Train Loss: 0.0003, Val Loss: 0.7161, Val Accuracy: 82.24%\n",
      "Epoch 387/800, Train Loss: 0.0002, Val Loss: 0.6665, Val Accuracy: 82.24%\n",
      "Epoch 388/800, Train Loss: 0.0002, Val Loss: 0.6797, Val Accuracy: 83.18%\n",
      "Epoch 389/800, Train Loss: 0.0001, Val Loss: 0.6633, Val Accuracy: 82.24%\n",
      "Epoch 390/800, Train Loss: 0.0002, Val Loss: 0.6929, Val Accuracy: 82.24%\n",
      "Epoch 391/800, Train Loss: 0.0002, Val Loss: 0.6837, Val Accuracy: 83.18%\n",
      "Epoch 392/800, Train Loss: 0.0002, Val Loss: 0.7172, Val Accuracy: 83.18%\n",
      "Epoch 393/800, Train Loss: 0.0002, Val Loss: 0.6925, Val Accuracy: 82.24%\n",
      "Epoch 394/800, Train Loss: 0.0002, Val Loss: 0.6915, Val Accuracy: 84.11%\n",
      "Epoch 395/800, Train Loss: 0.0002, Val Loss: 0.6927, Val Accuracy: 84.11%\n",
      "Epoch 396/800, Train Loss: 0.0001, Val Loss: 0.6597, Val Accuracy: 82.24%\n",
      "Epoch 397/800, Train Loss: 0.0002, Val Loss: 0.6776, Val Accuracy: 82.24%\n",
      "Epoch 398/800, Train Loss: 0.0006, Val Loss: 0.6624, Val Accuracy: 82.24%\n",
      "Epoch 399/800, Train Loss: 0.0001, Val Loss: 0.7756, Val Accuracy: 75.70%\n",
      "Epoch 400/800, Train Loss: 0.0003, Val Loss: 0.7391, Val Accuracy: 78.50%\n",
      "Epoch 401/800, Train Loss: 0.0002, Val Loss: 0.6884, Val Accuracy: 78.50%\n",
      "Epoch 402/800, Train Loss: 0.0002, Val Loss: 0.6624, Val Accuracy: 79.44%\n",
      "Epoch 403/800, Train Loss: 0.0002, Val Loss: 0.7331, Val Accuracy: 78.50%\n",
      "Epoch 404/800, Train Loss: 0.0001, Val Loss: 0.7078, Val Accuracy: 78.50%\n",
      "Epoch 405/800, Train Loss: 0.0001, Val Loss: 0.7208, Val Accuracy: 78.50%\n",
      "Epoch 406/800, Train Loss: 0.0002, Val Loss: 0.7144, Val Accuracy: 79.44%\n",
      "Epoch 407/800, Train Loss: 0.0002, Val Loss: 0.7487, Val Accuracy: 80.37%\n",
      "Epoch 408/800, Train Loss: 0.0006, Val Loss: 0.7582, Val Accuracy: 80.37%\n",
      "Epoch 409/800, Train Loss: 0.0003, Val Loss: 0.9852, Val Accuracy: 77.57%\n",
      "Epoch 410/800, Train Loss: 0.0002, Val Loss: 0.8570, Val Accuracy: 79.44%\n",
      "Epoch 411/800, Train Loss: 0.0003, Val Loss: 0.8490, Val Accuracy: 80.37%\n",
      "Epoch 412/800, Train Loss: 0.0002, Val Loss: 0.8083, Val Accuracy: 80.37%\n",
      "Epoch 413/800, Train Loss: 0.0001, Val Loss: 0.8180, Val Accuracy: 80.37%\n",
      "Epoch 414/800, Train Loss: 0.0001, Val Loss: 0.8051, Val Accuracy: 81.31%\n",
      "Epoch 415/800, Train Loss: 0.0001, Val Loss: 0.8110, Val Accuracy: 80.37%\n",
      "Epoch 416/800, Train Loss: 0.0001, Val Loss: 0.8344, Val Accuracy: 80.37%\n",
      "Epoch 417/800, Train Loss: 0.0002, Val Loss: 0.8474, Val Accuracy: 76.64%\n",
      "Epoch 418/800, Train Loss: 0.0002, Val Loss: 0.7793, Val Accuracy: 80.37%\n",
      "Epoch 419/800, Train Loss: 0.0007, Val Loss: 0.7851, Val Accuracy: 80.37%\n",
      "Epoch 420/800, Train Loss: 0.0001, Val Loss: 0.7620, Val Accuracy: 81.31%\n",
      "Epoch 421/800, Train Loss: 0.0002, Val Loss: 0.7631, Val Accuracy: 81.31%\n",
      "Epoch 422/800, Train Loss: 0.0002, Val Loss: 0.7767, Val Accuracy: 80.37%\n",
      "Epoch 423/800, Train Loss: 0.0008, Val Loss: 0.7990, Val Accuracy: 81.31%\n",
      "Epoch 424/800, Train Loss: 0.0010, Val Loss: 1.4413, Val Accuracy: 71.03%\n",
      "Epoch 425/800, Train Loss: 0.0019, Val Loss: 0.8848, Val Accuracy: 76.64%\n",
      "Epoch 426/800, Train Loss: 0.0011, Val Loss: 0.6976, Val Accuracy: 81.31%\n",
      "Epoch 427/800, Train Loss: 0.0006, Val Loss: 0.7093, Val Accuracy: 79.44%\n",
      "Epoch 428/800, Train Loss: 0.0002, Val Loss: 0.6620, Val Accuracy: 81.31%\n",
      "Epoch 429/800, Train Loss: 0.0008, Val Loss: 0.7122, Val Accuracy: 80.37%\n",
      "Epoch 430/800, Train Loss: 0.0002, Val Loss: 0.8900, Val Accuracy: 81.31%\n",
      "Epoch 431/800, Train Loss: 0.0078, Val Loss: 1.0049, Val Accuracy: 74.77%\n",
      "Epoch 432/800, Train Loss: 0.0007, Val Loss: 0.6851, Val Accuracy: 78.50%\n",
      "Epoch 433/800, Train Loss: 0.0018, Val Loss: 0.8435, Val Accuracy: 79.44%\n",
      "Epoch 434/800, Train Loss: 0.0076, Val Loss: 0.8870, Val Accuracy: 78.50%\n",
      "Epoch 435/800, Train Loss: 0.0207, Val Loss: 1.3700, Val Accuracy: 73.83%\n",
      "Epoch 436/800, Train Loss: 0.0677, Val Loss: 2.1907, Val Accuracy: 52.34%\n",
      "Epoch 437/800, Train Loss: 0.0454, Val Loss: 3.2163, Val Accuracy: 52.34%\n",
      "Epoch 438/800, Train Loss: 0.0191, Val Loss: 0.8101, Val Accuracy: 78.50%\n",
      "Epoch 439/800, Train Loss: 0.0151, Val Loss: 1.1034, Val Accuracy: 69.16%\n",
      "Epoch 440/800, Train Loss: 0.0305, Val Loss: 1.9910, Val Accuracy: 61.68%\n",
      "Epoch 441/800, Train Loss: 0.0491, Val Loss: 2.2981, Val Accuracy: 63.55%\n",
      "Epoch 442/800, Train Loss: 0.1186, Val Loss: 2.2882, Val Accuracy: 57.94%\n",
      "Epoch 443/800, Train Loss: 0.0756, Val Loss: 1.4391, Val Accuracy: 68.22%\n",
      "Epoch 444/800, Train Loss: 0.0983, Val Loss: 1.2061, Val Accuracy: 67.29%\n",
      "Epoch 445/800, Train Loss: 0.1644, Val Loss: 1.3607, Val Accuracy: 63.55%\n",
      "Epoch 446/800, Train Loss: 0.0618, Val Loss: 1.1849, Val Accuracy: 73.83%\n",
      "Epoch 447/800, Train Loss: 0.0284, Val Loss: 1.0097, Val Accuracy: 77.57%\n",
      "Epoch 448/800, Train Loss: 0.0136, Val Loss: 1.0501, Val Accuracy: 73.83%\n",
      "Epoch 449/800, Train Loss: 0.0042, Val Loss: 0.8569, Val Accuracy: 80.37%\n",
      "Epoch 450/800, Train Loss: 0.0015, Val Loss: 0.8225, Val Accuracy: 82.24%\n",
      "Epoch 451/800, Train Loss: 0.0109, Val Loss: 0.9619, Val Accuracy: 77.57%\n",
      "Epoch 452/800, Train Loss: 0.0013, Val Loss: 0.8801, Val Accuracy: 80.37%\n",
      "Epoch 453/800, Train Loss: 0.0010, Val Loss: 0.8774, Val Accuracy: 82.24%\n",
      "Epoch 454/800, Train Loss: 0.0006, Val Loss: 0.8707, Val Accuracy: 82.24%\n",
      "Epoch 455/800, Train Loss: 0.0008, Val Loss: 0.8765, Val Accuracy: 81.31%\n",
      "Epoch 456/800, Train Loss: 0.0011, Val Loss: 0.8635, Val Accuracy: 81.31%\n",
      "Epoch 457/800, Train Loss: 0.0008, Val Loss: 0.8253, Val Accuracy: 82.24%\n",
      "Epoch 458/800, Train Loss: 0.0003, Val Loss: 0.8479, Val Accuracy: 81.31%\n",
      "Epoch 459/800, Train Loss: 0.0012, Val Loss: 0.8493, Val Accuracy: 81.31%\n",
      "Epoch 460/800, Train Loss: 0.0002, Val Loss: 0.8662, Val Accuracy: 80.37%\n",
      "Epoch 461/800, Train Loss: 0.0010, Val Loss: 0.8513, Val Accuracy: 81.31%\n",
      "Epoch 462/800, Train Loss: 0.0007, Val Loss: 0.8963, Val Accuracy: 79.44%\n",
      "Epoch 463/800, Train Loss: 0.0008, Val Loss: 0.8918, Val Accuracy: 79.44%\n",
      "Epoch 464/800, Train Loss: 0.0055, Val Loss: 0.8760, Val Accuracy: 81.31%\n",
      "Epoch 465/800, Train Loss: 0.0117, Val Loss: 1.1220, Val Accuracy: 72.90%\n",
      "Epoch 466/800, Train Loss: 0.0125, Val Loss: 0.9266, Val Accuracy: 80.37%\n",
      "Epoch 467/800, Train Loss: 0.0039, Val Loss: 0.9558, Val Accuracy: 81.31%\n",
      "Epoch 468/800, Train Loss: 0.0060, Val Loss: 0.9524, Val Accuracy: 79.44%\n",
      "Epoch 469/800, Train Loss: 0.0140, Val Loss: 1.3998, Val Accuracy: 71.03%\n",
      "Epoch 470/800, Train Loss: 0.0027, Val Loss: 0.8934, Val Accuracy: 78.50%\n",
      "Epoch 471/800, Train Loss: 0.0052, Val Loss: 0.9143, Val Accuracy: 77.57%\n",
      "Epoch 472/800, Train Loss: 0.0014, Val Loss: 1.0550, Val Accuracy: 80.37%\n",
      "Epoch 473/800, Train Loss: 0.0032, Val Loss: 1.0893, Val Accuracy: 79.44%\n",
      "Epoch 474/800, Train Loss: 0.0017, Val Loss: 0.9310, Val Accuracy: 82.24%\n",
      "Epoch 475/800, Train Loss: 0.0141, Val Loss: 1.3213, Val Accuracy: 67.29%\n",
      "Epoch 476/800, Train Loss: 0.0110, Val Loss: 0.8641, Val Accuracy: 76.64%\n",
      "Epoch 477/800, Train Loss: 0.0024, Val Loss: 0.8062, Val Accuracy: 82.24%\n",
      "Epoch 478/800, Train Loss: 0.0011, Val Loss: 0.7250, Val Accuracy: 83.18%\n",
      "Epoch 479/800, Train Loss: 0.0005, Val Loss: 0.6962, Val Accuracy: 83.18%\n",
      "Epoch 480/800, Train Loss: 0.0016, Val Loss: 0.6910, Val Accuracy: 83.18%\n",
      "Epoch 481/800, Train Loss: 0.0005, Val Loss: 0.6980, Val Accuracy: 83.18%\n",
      "Epoch 482/800, Train Loss: 0.0008, Val Loss: 0.6697, Val Accuracy: 83.18%\n",
      "Epoch 483/800, Train Loss: 0.0007, Val Loss: 0.7120, Val Accuracy: 84.11%\n",
      "Epoch 484/800, Train Loss: 0.0004, Val Loss: 0.7484, Val Accuracy: 83.18%\n",
      "Epoch 485/800, Train Loss: 0.0002, Val Loss: 0.6945, Val Accuracy: 83.18%\n",
      "Epoch 486/800, Train Loss: 0.0003, Val Loss: 0.6974, Val Accuracy: 84.11%\n",
      "Epoch 487/800, Train Loss: 0.0011, Val Loss: 0.7040, Val Accuracy: 85.98%\n",
      "Epoch 488/800, Train Loss: 0.0013, Val Loss: 0.7362, Val Accuracy: 78.50%\n",
      "Epoch 489/800, Train Loss: 0.0017, Val Loss: 0.7722, Val Accuracy: 79.44%\n",
      "Epoch 490/800, Train Loss: 0.0007, Val Loss: 0.7318, Val Accuracy: 82.24%\n",
      "Epoch 491/800, Train Loss: 0.0006, Val Loss: 0.7151, Val Accuracy: 83.18%\n",
      "Epoch 492/800, Train Loss: 0.0002, Val Loss: 0.6902, Val Accuracy: 83.18%\n",
      "Epoch 493/800, Train Loss: 0.0002, Val Loss: 0.6972, Val Accuracy: 81.31%\n",
      "Epoch 494/800, Train Loss: 0.0003, Val Loss: 0.7380, Val Accuracy: 81.31%\n",
      "Epoch 495/800, Train Loss: 0.0003, Val Loss: 0.7150, Val Accuracy: 82.24%\n",
      "Epoch 496/800, Train Loss: 0.0001, Val Loss: 0.7103, Val Accuracy: 82.24%\n",
      "Epoch 497/800, Train Loss: 0.0002, Val Loss: 0.7099, Val Accuracy: 82.24%\n",
      "Epoch 498/800, Train Loss: 0.0002, Val Loss: 0.7362, Val Accuracy: 81.31%\n",
      "Epoch 499/800, Train Loss: 0.0006, Val Loss: 0.7006, Val Accuracy: 82.24%\n",
      "Epoch 500/800, Train Loss: 0.0003, Val Loss: 0.7044, Val Accuracy: 82.24%\n",
      "Epoch 501/800, Train Loss: 0.0002, Val Loss: 0.7121, Val Accuracy: 82.24%\n",
      "Epoch 502/800, Train Loss: 0.0002, Val Loss: 0.6977, Val Accuracy: 83.18%\n",
      "Epoch 503/800, Train Loss: 0.0094, Val Loss: 0.7079, Val Accuracy: 83.18%\n",
      "Epoch 504/800, Train Loss: 0.1242, Val Loss: 4.1307, Val Accuracy: 49.53%\n",
      "Epoch 505/800, Train Loss: 0.0727, Val Loss: 2.2557, Val Accuracy: 60.75%\n",
      "Epoch 506/800, Train Loss: 0.0810, Val Loss: 2.1913, Val Accuracy: 61.68%\n",
      "Epoch 507/800, Train Loss: 0.0353, Val Loss: 1.3820, Val Accuracy: 63.55%\n",
      "Epoch 508/800, Train Loss: 0.0128, Val Loss: 1.0557, Val Accuracy: 73.83%\n",
      "Epoch 509/800, Train Loss: 0.0099, Val Loss: 1.2095, Val Accuracy: 71.96%\n",
      "Epoch 510/800, Train Loss: 0.0107, Val Loss: 1.2146, Val Accuracy: 69.16%\n",
      "Epoch 511/800, Train Loss: 0.0086, Val Loss: 0.8020, Val Accuracy: 79.44%\n",
      "Epoch 512/800, Train Loss: 0.0050, Val Loss: 1.3563, Val Accuracy: 71.96%\n",
      "Epoch 513/800, Train Loss: 0.0046, Val Loss: 1.1274, Val Accuracy: 76.64%\n",
      "Epoch 514/800, Train Loss: 0.0020, Val Loss: 0.9592, Val Accuracy: 74.77%\n",
      "Epoch 515/800, Train Loss: 0.0010, Val Loss: 0.8949, Val Accuracy: 75.70%\n",
      "Epoch 516/800, Train Loss: 0.0008, Val Loss: 0.8993, Val Accuracy: 75.70%\n",
      "Epoch 517/800, Train Loss: 0.0006, Val Loss: 0.8992, Val Accuracy: 76.64%\n",
      "Epoch 518/800, Train Loss: 0.0016, Val Loss: 0.9064, Val Accuracy: 77.57%\n",
      "Epoch 519/800, Train Loss: 0.0015, Val Loss: 0.9058, Val Accuracy: 77.57%\n",
      "Epoch 520/800, Train Loss: 0.0005, Val Loss: 0.9038, Val Accuracy: 77.57%\n",
      "Epoch 521/800, Train Loss: 0.0006, Val Loss: 0.9532, Val Accuracy: 79.44%\n",
      "Epoch 522/800, Train Loss: 0.0008, Val Loss: 0.9262, Val Accuracy: 78.50%\n",
      "Epoch 523/800, Train Loss: 0.0004, Val Loss: 0.8935, Val Accuracy: 74.77%\n",
      "Epoch 524/800, Train Loss: 0.0004, Val Loss: 0.9338, Val Accuracy: 75.70%\n",
      "Epoch 525/800, Train Loss: 0.0002, Val Loss: 0.8454, Val Accuracy: 80.37%\n",
      "Epoch 526/800, Train Loss: 0.0004, Val Loss: 0.8416, Val Accuracy: 79.44%\n",
      "Epoch 527/800, Train Loss: 0.0002, Val Loss: 0.8700, Val Accuracy: 79.44%\n",
      "Epoch 528/800, Train Loss: 0.0004, Val Loss: 0.8919, Val Accuracy: 78.50%\n",
      "Epoch 529/800, Train Loss: 0.0004, Val Loss: 0.8291, Val Accuracy: 80.37%\n",
      "Epoch 530/800, Train Loss: 0.0002, Val Loss: 0.8567, Val Accuracy: 79.44%\n",
      "Epoch 531/800, Train Loss: 0.0003, Val Loss: 0.8619, Val Accuracy: 79.44%\n",
      "Epoch 532/800, Train Loss: 0.0002, Val Loss: 0.8232, Val Accuracy: 81.31%\n",
      "Epoch 533/800, Train Loss: 0.0002, Val Loss: 0.8258, Val Accuracy: 79.44%\n",
      "Epoch 534/800, Train Loss: 0.0001, Val Loss: 0.8417, Val Accuracy: 78.50%\n",
      "Epoch 535/800, Train Loss: 0.0002, Val Loss: 0.8099, Val Accuracy: 81.31%\n",
      "Epoch 536/800, Train Loss: 0.0003, Val Loss: 0.8540, Val Accuracy: 81.31%\n",
      "Epoch 537/800, Train Loss: 0.0002, Val Loss: 0.8444, Val Accuracy: 81.31%\n",
      "Epoch 538/800, Train Loss: 0.0002, Val Loss: 0.8665, Val Accuracy: 81.31%\n",
      "Epoch 539/800, Train Loss: 0.0004, Val Loss: 0.8248, Val Accuracy: 82.24%\n",
      "Epoch 540/800, Train Loss: 0.0001, Val Loss: 0.8139, Val Accuracy: 81.31%\n",
      "Epoch 541/800, Train Loss: 0.0004, Val Loss: 0.8033, Val Accuracy: 81.31%\n",
      "Epoch 542/800, Train Loss: 0.0002, Val Loss: 0.8605, Val Accuracy: 81.31%\n",
      "Epoch 543/800, Train Loss: 0.0001, Val Loss: 0.8116, Val Accuracy: 82.24%\n",
      "Epoch 544/800, Train Loss: 0.0001, Val Loss: 0.8389, Val Accuracy: 81.31%\n",
      "Epoch 545/800, Train Loss: 0.0006, Val Loss: 0.8375, Val Accuracy: 81.31%\n",
      "Epoch 546/800, Train Loss: 0.0002, Val Loss: 0.9486, Val Accuracy: 80.37%\n",
      "Epoch 547/800, Train Loss: 0.0002, Val Loss: 0.9537, Val Accuracy: 79.44%\n",
      "Epoch 548/800, Train Loss: 0.0005, Val Loss: 0.9420, Val Accuracy: 79.44%\n",
      "Epoch 549/800, Train Loss: 0.0004, Val Loss: 0.9223, Val Accuracy: 81.31%\n",
      "Epoch 550/800, Train Loss: 0.0002, Val Loss: 0.7846, Val Accuracy: 82.24%\n",
      "Epoch 551/800, Train Loss: 0.0002, Val Loss: 0.8141, Val Accuracy: 82.24%\n",
      "Epoch 552/800, Train Loss: 0.0002, Val Loss: 0.7907, Val Accuracy: 82.24%\n",
      "Epoch 553/800, Train Loss: 0.0003, Val Loss: 0.8520, Val Accuracy: 82.24%\n",
      "Epoch 554/800, Train Loss: 0.0001, Val Loss: 0.7843, Val Accuracy: 81.31%\n",
      "Epoch 555/800, Train Loss: 0.0004, Val Loss: 0.8145, Val Accuracy: 81.31%\n",
      "Epoch 556/800, Train Loss: 0.0001, Val Loss: 0.8079, Val Accuracy: 80.37%\n",
      "Epoch 557/800, Train Loss: 0.0001, Val Loss: 0.7935, Val Accuracy: 83.18%\n",
      "Epoch 558/800, Train Loss: 0.0002, Val Loss: 0.8436, Val Accuracy: 81.31%\n",
      "Epoch 559/800, Train Loss: 0.0001, Val Loss: 0.8022, Val Accuracy: 82.24%\n",
      "Epoch 560/800, Train Loss: 0.0001, Val Loss: 0.7899, Val Accuracy: 82.24%\n",
      "Epoch 561/800, Train Loss: 0.0087, Val Loss: 0.7610, Val Accuracy: 78.50%\n",
      "Epoch 562/800, Train Loss: 0.0673, Val Loss: 1.4133, Val Accuracy: 68.22%\n",
      "Epoch 563/800, Train Loss: 0.0538, Val Loss: 1.0957, Val Accuracy: 73.83%\n",
      "Epoch 564/800, Train Loss: 0.0530, Val Loss: 1.1741, Val Accuracy: 72.90%\n",
      "Epoch 565/800, Train Loss: 0.0221, Val Loss: 1.2653, Val Accuracy: 69.16%\n",
      "Epoch 566/800, Train Loss: 0.0036, Val Loss: 1.3224, Val Accuracy: 72.90%\n",
      "Epoch 567/800, Train Loss: 0.0031, Val Loss: 1.0175, Val Accuracy: 73.83%\n",
      "Epoch 568/800, Train Loss: 0.0014, Val Loss: 0.9333, Val Accuracy: 74.77%\n",
      "Epoch 569/800, Train Loss: 0.0050, Val Loss: 0.8434, Val Accuracy: 78.50%\n",
      "Epoch 570/800, Train Loss: 0.0036, Val Loss: 0.8826, Val Accuracy: 75.70%\n",
      "Epoch 571/800, Train Loss: 0.0142, Val Loss: 0.7579, Val Accuracy: 78.50%\n",
      "Epoch 572/800, Train Loss: 0.0106, Val Loss: 0.8512, Val Accuracy: 80.37%\n",
      "Epoch 573/800, Train Loss: 0.0017, Val Loss: 0.9027, Val Accuracy: 81.31%\n",
      "Epoch 574/800, Train Loss: 0.0067, Val Loss: 0.9532, Val Accuracy: 78.50%\n",
      "Epoch 575/800, Train Loss: 0.0027, Val Loss: 0.8974, Val Accuracy: 79.44%\n",
      "Epoch 576/800, Train Loss: 0.0010, Val Loss: 0.8535, Val Accuracy: 81.31%\n",
      "Epoch 577/800, Train Loss: 0.0012, Val Loss: 0.8211, Val Accuracy: 83.18%\n",
      "Epoch 578/800, Train Loss: 0.0024, Val Loss: 0.7667, Val Accuracy: 85.05%\n",
      "Epoch 579/800, Train Loss: 0.0021, Val Loss: 0.6947, Val Accuracy: 85.05%\n",
      "Epoch 580/800, Train Loss: 0.0032, Val Loss: 1.1873, Val Accuracy: 79.44%\n",
      "Epoch 581/800, Train Loss: 0.0019, Val Loss: 0.8106, Val Accuracy: 82.24%\n",
      "Epoch 582/800, Train Loss: 0.0007, Val Loss: 0.7536, Val Accuracy: 83.18%\n",
      "Epoch 583/800, Train Loss: 0.0006, Val Loss: 0.7182, Val Accuracy: 85.05%\n",
      "Epoch 584/800, Train Loss: 0.0004, Val Loss: 0.7246, Val Accuracy: 84.11%\n",
      "Epoch 585/800, Train Loss: 0.0006, Val Loss: 0.7679, Val Accuracy: 81.31%\n",
      "Epoch 586/800, Train Loss: 0.0002, Val Loss: 0.7206, Val Accuracy: 84.11%\n",
      "Epoch 587/800, Train Loss: 0.0004, Val Loss: 0.6995, Val Accuracy: 83.18%\n",
      "Epoch 588/800, Train Loss: 0.0002, Val Loss: 0.7379, Val Accuracy: 81.31%\n",
      "Epoch 589/800, Train Loss: 0.0002, Val Loss: 0.7338, Val Accuracy: 82.24%\n",
      "Epoch 590/800, Train Loss: 0.0017, Val Loss: 0.7127, Val Accuracy: 84.11%\n",
      "Epoch 591/800, Train Loss: 0.0024, Val Loss: 0.9382, Val Accuracy: 78.50%\n",
      "Epoch 592/800, Train Loss: 0.0011, Val Loss: 0.8013, Val Accuracy: 80.37%\n",
      "Epoch 593/800, Train Loss: 0.0011, Val Loss: 0.8488, Val Accuracy: 80.37%\n",
      "Epoch 594/800, Train Loss: 0.0004, Val Loss: 0.8293, Val Accuracy: 80.37%\n",
      "Epoch 595/800, Train Loss: 0.0003, Val Loss: 0.7796, Val Accuracy: 82.24%\n",
      "Epoch 596/800, Train Loss: 0.0002, Val Loss: 0.7865, Val Accuracy: 82.24%\n",
      "Epoch 597/800, Train Loss: 0.0004, Val Loss: 0.7997, Val Accuracy: 82.24%\n",
      "Epoch 598/800, Train Loss: 0.0002, Val Loss: 0.7988, Val Accuracy: 81.31%\n",
      "Epoch 599/800, Train Loss: 0.0005, Val Loss: 0.8346, Val Accuracy: 81.31%\n",
      "Epoch 600/800, Train Loss: 0.0003, Val Loss: 0.8418, Val Accuracy: 81.31%\n",
      "Epoch 601/800, Train Loss: 0.0002, Val Loss: 0.8078, Val Accuracy: 82.24%\n",
      "Epoch 602/800, Train Loss: 0.0010, Val Loss: 0.7646, Val Accuracy: 84.11%\n",
      "Epoch 603/800, Train Loss: 0.0001, Val Loss: 0.7744, Val Accuracy: 84.11%\n",
      "Epoch 604/800, Train Loss: 0.0002, Val Loss: 0.7749, Val Accuracy: 83.18%\n",
      "Epoch 605/800, Train Loss: 0.0001, Val Loss: 0.7775, Val Accuracy: 83.18%\n",
      "Epoch 606/800, Train Loss: 0.0001, Val Loss: 0.7667, Val Accuracy: 82.24%\n",
      "Epoch 607/800, Train Loss: 0.0002, Val Loss: 0.7926, Val Accuracy: 82.24%\n",
      "Epoch 608/800, Train Loss: 0.0001, Val Loss: 0.7763, Val Accuracy: 83.18%\n",
      "Epoch 609/800, Train Loss: 0.0002, Val Loss: 0.7562, Val Accuracy: 83.18%\n",
      "Epoch 610/800, Train Loss: 0.0001, Val Loss: 0.7963, Val Accuracy: 82.24%\n",
      "Epoch 611/800, Train Loss: 0.0001, Val Loss: 0.7619, Val Accuracy: 84.11%\n",
      "Epoch 612/800, Train Loss: 0.0002, Val Loss: 0.7777, Val Accuracy: 84.11%\n",
      "Epoch 613/800, Train Loss: 0.0001, Val Loss: 0.7953, Val Accuracy: 83.18%\n",
      "Epoch 614/800, Train Loss: 0.0002, Val Loss: 0.7991, Val Accuracy: 82.24%\n",
      "Epoch 615/800, Train Loss: 0.0002, Val Loss: 0.7950, Val Accuracy: 83.18%\n",
      "Epoch 616/800, Train Loss: 0.0001, Val Loss: 0.7756, Val Accuracy: 83.18%\n",
      "Epoch 617/800, Train Loss: 0.0002, Val Loss: 0.7882, Val Accuracy: 83.18%\n",
      "Epoch 618/800, Train Loss: 0.0003, Val Loss: 0.7440, Val Accuracy: 83.18%\n",
      "Epoch 619/800, Train Loss: 0.0001, Val Loss: 0.7407, Val Accuracy: 83.18%\n",
      "Epoch 620/800, Train Loss: 0.0001, Val Loss: 0.7729, Val Accuracy: 82.24%\n",
      "Epoch 621/800, Train Loss: 0.0001, Val Loss: 0.7749, Val Accuracy: 82.24%\n",
      "Epoch 622/800, Train Loss: 0.0001, Val Loss: 0.7831, Val Accuracy: 82.24%\n",
      "Epoch 623/800, Train Loss: 0.0002, Val Loss: 0.7649, Val Accuracy: 84.11%\n",
      "Epoch 624/800, Train Loss: 0.0001, Val Loss: 0.7443, Val Accuracy: 83.18%\n",
      "Epoch 625/800, Train Loss: 0.0001, Val Loss: 0.7858, Val Accuracy: 82.24%\n",
      "Epoch 626/800, Train Loss: 0.0001, Val Loss: 0.7500, Val Accuracy: 82.24%\n",
      "Epoch 627/800, Train Loss: 0.0001, Val Loss: 0.7630, Val Accuracy: 83.18%\n",
      "Epoch 628/800, Train Loss: 0.0001, Val Loss: 0.7420, Val Accuracy: 82.24%\n",
      "Epoch 629/800, Train Loss: 0.0000, Val Loss: 0.7387, Val Accuracy: 82.24%\n",
      "Epoch 630/800, Train Loss: 0.0000, Val Loss: 0.7649, Val Accuracy: 83.18%\n",
      "Epoch 631/800, Train Loss: 0.0001, Val Loss: 0.7541, Val Accuracy: 84.11%\n",
      "Epoch 632/800, Train Loss: 0.0002, Val Loss: 0.8172, Val Accuracy: 82.24%\n",
      "Epoch 633/800, Train Loss: 0.0001, Val Loss: 0.7901, Val Accuracy: 82.24%\n",
      "Epoch 634/800, Train Loss: 0.0001, Val Loss: 0.8128, Val Accuracy: 82.24%\n",
      "Epoch 635/800, Train Loss: 0.0001, Val Loss: 0.7626, Val Accuracy: 81.31%\n",
      "Epoch 636/800, Train Loss: 0.0001, Val Loss: 0.7179, Val Accuracy: 83.18%\n",
      "Epoch 637/800, Train Loss: 0.0001, Val Loss: 0.7307, Val Accuracy: 84.11%\n",
      "Epoch 638/800, Train Loss: 0.0000, Val Loss: 0.7161, Val Accuracy: 84.11%\n",
      "Epoch 639/800, Train Loss: 0.0001, Val Loss: 0.7311, Val Accuracy: 84.11%\n",
      "Epoch 640/800, Train Loss: 0.0001, Val Loss: 0.7293, Val Accuracy: 84.11%\n",
      "Epoch 641/800, Train Loss: 0.0001, Val Loss: 0.7263, Val Accuracy: 84.11%\n",
      "Epoch 642/800, Train Loss: 0.0000, Val Loss: 0.7453, Val Accuracy: 85.05%\n",
      "Epoch 643/800, Train Loss: 0.0062, Val Loss: 0.7424, Val Accuracy: 84.11%\n",
      "Epoch 644/800, Train Loss: 0.0468, Val Loss: 1.6947, Val Accuracy: 65.42%\n",
      "Epoch 645/800, Train Loss: 0.0357, Val Loss: 0.7715, Val Accuracy: 78.50%\n",
      "Epoch 646/800, Train Loss: 0.0456, Val Loss: 0.7823, Val Accuracy: 76.64%\n",
      "Epoch 647/800, Train Loss: 0.0279, Val Loss: 1.0935, Val Accuracy: 71.96%\n",
      "Epoch 648/800, Train Loss: 0.0313, Val Loss: 0.8712, Val Accuracy: 77.57%\n",
      "Epoch 649/800, Train Loss: 0.0162, Val Loss: 1.0409, Val Accuracy: 78.50%\n",
      "Epoch 650/800, Train Loss: 0.0422, Val Loss: 1.0286, Val Accuracy: 69.16%\n",
      "Epoch 651/800, Train Loss: 0.0443, Val Loss: 1.8656, Val Accuracy: 67.29%\n",
      "Epoch 652/800, Train Loss: 0.0525, Val Loss: 1.0262, Val Accuracy: 68.22%\n",
      "Epoch 653/800, Train Loss: 0.0130, Val Loss: 0.9668, Val Accuracy: 74.77%\n",
      "Epoch 654/800, Train Loss: 0.0158, Val Loss: 2.0122, Val Accuracy: 61.68%\n",
      "Epoch 655/800, Train Loss: 0.0154, Val Loss: 1.5189, Val Accuracy: 70.09%\n",
      "Epoch 656/800, Train Loss: 0.0076, Val Loss: 1.0001, Val Accuracy: 75.70%\n",
      "Epoch 657/800, Train Loss: 0.0015, Val Loss: 0.8553, Val Accuracy: 80.37%\n",
      "Epoch 658/800, Train Loss: 0.0012, Val Loss: 0.8405, Val Accuracy: 79.44%\n",
      "Epoch 659/800, Train Loss: 0.0007, Val Loss: 0.9530, Val Accuracy: 78.50%\n",
      "Epoch 660/800, Train Loss: 0.0016, Val Loss: 0.8950, Val Accuracy: 78.50%\n",
      "Epoch 661/800, Train Loss: 0.0017, Val Loss: 0.7788, Val Accuracy: 80.37%\n",
      "Epoch 662/800, Train Loss: 0.0104, Val Loss: 1.4647, Val Accuracy: 71.96%\n",
      "Epoch 663/800, Train Loss: 0.0049, Val Loss: 1.0567, Val Accuracy: 74.77%\n",
      "Epoch 664/800, Train Loss: 0.0149, Val Loss: 1.2864, Val Accuracy: 70.09%\n",
      "Epoch 665/800, Train Loss: 0.0219, Val Loss: 0.7737, Val Accuracy: 78.50%\n",
      "Epoch 666/800, Train Loss: 0.0073, Val Loss: 1.1011, Val Accuracy: 71.96%\n",
      "Epoch 667/800, Train Loss: 0.0042, Val Loss: 0.7922, Val Accuracy: 80.37%\n",
      "Epoch 668/800, Train Loss: 0.0013, Val Loss: 0.9968, Val Accuracy: 73.83%\n",
      "Epoch 669/800, Train Loss: 0.0010, Val Loss: 0.9754, Val Accuracy: 77.57%\n",
      "Epoch 670/800, Train Loss: 0.0005, Val Loss: 0.8263, Val Accuracy: 78.50%\n",
      "Epoch 671/800, Train Loss: 0.0003, Val Loss: 0.7657, Val Accuracy: 78.50%\n",
      "Epoch 672/800, Train Loss: 0.0004, Val Loss: 0.7647, Val Accuracy: 79.44%\n",
      "Epoch 673/800, Train Loss: 0.0002, Val Loss: 0.7496, Val Accuracy: 79.44%\n",
      "Epoch 674/800, Train Loss: 0.0003, Val Loss: 0.7731, Val Accuracy: 78.50%\n",
      "Epoch 675/800, Train Loss: 0.0005, Val Loss: 0.7748, Val Accuracy: 78.50%\n",
      "Epoch 676/800, Train Loss: 0.0005, Val Loss: 0.7803, Val Accuracy: 78.50%\n",
      "Epoch 677/800, Train Loss: 0.0002, Val Loss: 0.7628, Val Accuracy: 78.50%\n",
      "Epoch 678/800, Train Loss: 0.0004, Val Loss: 0.7376, Val Accuracy: 78.50%\n",
      "Epoch 679/800, Train Loss: 0.0002, Val Loss: 0.7425, Val Accuracy: 77.57%\n",
      "Epoch 680/800, Train Loss: 0.0003, Val Loss: 0.7796, Val Accuracy: 78.50%\n",
      "Epoch 681/800, Train Loss: 0.0002, Val Loss: 0.7356, Val Accuracy: 78.50%\n",
      "Epoch 682/800, Train Loss: 0.0003, Val Loss: 0.7602, Val Accuracy: 78.50%\n",
      "Epoch 683/800, Train Loss: 0.0002, Val Loss: 0.7608, Val Accuracy: 78.50%\n",
      "Epoch 684/800, Train Loss: 0.0001, Val Loss: 0.7811, Val Accuracy: 77.57%\n",
      "Epoch 685/800, Train Loss: 0.0003, Val Loss: 0.7765, Val Accuracy: 76.64%\n",
      "Epoch 686/800, Train Loss: 0.0002, Val Loss: 0.7772, Val Accuracy: 78.50%\n",
      "Epoch 687/800, Train Loss: 0.0001, Val Loss: 0.7674, Val Accuracy: 79.44%\n",
      "Epoch 688/800, Train Loss: 0.0002, Val Loss: 0.8063, Val Accuracy: 77.57%\n",
      "Epoch 689/800, Train Loss: 0.0001, Val Loss: 0.7605, Val Accuracy: 77.57%\n",
      "Epoch 690/800, Train Loss: 0.0001, Val Loss: 0.7471, Val Accuracy: 79.44%\n",
      "Epoch 691/800, Train Loss: 0.0001, Val Loss: 0.7668, Val Accuracy: 78.50%\n",
      "Epoch 692/800, Train Loss: 0.0001, Val Loss: 0.7664, Val Accuracy: 78.50%\n",
      "Epoch 693/800, Train Loss: 0.0002, Val Loss: 0.7405, Val Accuracy: 78.50%\n",
      "Epoch 694/800, Train Loss: 0.0002, Val Loss: 0.7204, Val Accuracy: 79.44%\n",
      "Epoch 695/800, Train Loss: 0.0001, Val Loss: 0.7356, Val Accuracy: 77.57%\n",
      "Epoch 696/800, Train Loss: 0.0001, Val Loss: 0.7616, Val Accuracy: 78.50%\n",
      "Epoch 697/800, Train Loss: 0.0039, Val Loss: 0.7701, Val Accuracy: 76.64%\n",
      "Epoch 698/800, Train Loss: 0.0091, Val Loss: 0.7521, Val Accuracy: 80.37%\n",
      "Epoch 699/800, Train Loss: 0.0104, Val Loss: 1.0119, Val Accuracy: 75.70%\n",
      "Epoch 700/800, Train Loss: 0.0038, Val Loss: 0.9791, Val Accuracy: 76.64%\n",
      "Epoch 701/800, Train Loss: 0.0208, Val Loss: 0.6725, Val Accuracy: 79.44%\n",
      "Epoch 702/800, Train Loss: 0.0247, Val Loss: 1.0157, Val Accuracy: 77.57%\n",
      "Epoch 703/800, Train Loss: 0.0179, Val Loss: 1.4008, Val Accuracy: 73.83%\n",
      "Epoch 704/800, Train Loss: 0.0264, Val Loss: 1.0208, Val Accuracy: 67.29%\n",
      "Epoch 705/800, Train Loss: 0.0116, Val Loss: 0.7867, Val Accuracy: 79.44%\n",
      "Epoch 706/800, Train Loss: 0.0044, Val Loss: 0.7738, Val Accuracy: 76.64%\n",
      "Epoch 707/800, Train Loss: 0.0031, Val Loss: 0.6450, Val Accuracy: 78.50%\n",
      "Epoch 708/800, Train Loss: 0.0010, Val Loss: 0.6225, Val Accuracy: 79.44%\n",
      "Epoch 709/800, Train Loss: 0.0006, Val Loss: 0.6191, Val Accuracy: 82.24%\n",
      "Epoch 710/800, Train Loss: 0.0008, Val Loss: 0.6351, Val Accuracy: 82.24%\n",
      "Epoch 711/800, Train Loss: 0.0009, Val Loss: 0.6219, Val Accuracy: 82.24%\n",
      "Epoch 712/800, Train Loss: 0.0003, Val Loss: 0.5517, Val Accuracy: 85.05%\n",
      "Epoch 713/800, Train Loss: 0.0006, Val Loss: 0.5517, Val Accuracy: 84.11%\n",
      "Epoch 714/800, Train Loss: 0.0002, Val Loss: 0.5704, Val Accuracy: 84.11%\n",
      "Epoch 715/800, Train Loss: 0.0009, Val Loss: 0.5654, Val Accuracy: 85.05%\n",
      "Epoch 716/800, Train Loss: 0.0003, Val Loss: 0.5466, Val Accuracy: 86.92%\n",
      "Epoch 717/800, Train Loss: 0.0004, Val Loss: 0.5527, Val Accuracy: 85.98%\n",
      "Epoch 718/800, Train Loss: 0.0004, Val Loss: 0.5588, Val Accuracy: 85.05%\n",
      "Epoch 719/800, Train Loss: 0.0002, Val Loss: 0.5537, Val Accuracy: 84.11%\n",
      "Epoch 720/800, Train Loss: 0.0002, Val Loss: 0.5722, Val Accuracy: 83.18%\n",
      "Epoch 721/800, Train Loss: 0.0001, Val Loss: 0.5692, Val Accuracy: 85.05%\n",
      "Epoch 722/800, Train Loss: 0.0003, Val Loss: 0.5803, Val Accuracy: 84.11%\n",
      "Epoch 723/800, Train Loss: 0.0003, Val Loss: 0.6103, Val Accuracy: 83.18%\n",
      "Epoch 724/800, Train Loss: 0.0001, Val Loss: 0.5974, Val Accuracy: 84.11%\n",
      "Epoch 725/800, Train Loss: 0.0002, Val Loss: 0.5656, Val Accuracy: 84.11%\n",
      "Epoch 726/800, Train Loss: 0.0002, Val Loss: 0.6056, Val Accuracy: 84.11%\n",
      "Epoch 727/800, Train Loss: 0.0002, Val Loss: 0.6168, Val Accuracy: 85.05%\n",
      "Epoch 728/800, Train Loss: 0.0001, Val Loss: 0.5886, Val Accuracy: 84.11%\n",
      "Epoch 729/800, Train Loss: 0.0002, Val Loss: 0.6182, Val Accuracy: 85.05%\n",
      "Epoch 730/800, Train Loss: 0.0002, Val Loss: 0.5493, Val Accuracy: 83.18%\n",
      "Epoch 731/800, Train Loss: 0.0001, Val Loss: 0.5742, Val Accuracy: 84.11%\n",
      "Epoch 732/800, Train Loss: 0.0001, Val Loss: 0.5566, Val Accuracy: 82.24%\n",
      "Epoch 733/800, Train Loss: 0.0001, Val Loss: 0.5888, Val Accuracy: 83.18%\n",
      "Epoch 734/800, Train Loss: 0.0002, Val Loss: 0.6221, Val Accuracy: 85.05%\n",
      "Epoch 735/800, Train Loss: 0.0001, Val Loss: 0.5517, Val Accuracy: 85.05%\n",
      "Epoch 736/800, Train Loss: 0.0001, Val Loss: 0.5441, Val Accuracy: 84.11%\n",
      "Epoch 737/800, Train Loss: 0.0001, Val Loss: 0.5487, Val Accuracy: 84.11%\n",
      "Epoch 738/800, Train Loss: 0.0001, Val Loss: 0.5541, Val Accuracy: 82.24%\n",
      "Epoch 739/800, Train Loss: 0.0001, Val Loss: 0.5501, Val Accuracy: 84.11%\n",
      "Epoch 740/800, Train Loss: 0.0001, Val Loss: 0.5623, Val Accuracy: 84.11%\n",
      "Epoch 741/800, Train Loss: 0.0001, Val Loss: 0.5744, Val Accuracy: 83.18%\n",
      "Epoch 742/800, Train Loss: 0.0001, Val Loss: 0.5637, Val Accuracy: 84.11%\n",
      "Epoch 743/800, Train Loss: 0.0002, Val Loss: 0.5540, Val Accuracy: 82.24%\n",
      "Epoch 744/800, Train Loss: 0.0001, Val Loss: 0.5728, Val Accuracy: 84.11%\n",
      "Epoch 745/800, Train Loss: 0.0001, Val Loss: 0.5767, Val Accuracy: 83.18%\n",
      "Epoch 746/800, Train Loss: 0.0001, Val Loss: 0.6012, Val Accuracy: 83.18%\n",
      "Epoch 747/800, Train Loss: 0.0001, Val Loss: 0.5941, Val Accuracy: 84.11%\n",
      "Epoch 748/800, Train Loss: 0.0001, Val Loss: 0.5593, Val Accuracy: 83.18%\n",
      "Epoch 749/800, Train Loss: 0.0001, Val Loss: 0.5784, Val Accuracy: 84.11%\n",
      "Epoch 750/800, Train Loss: 0.0001, Val Loss: 0.5538, Val Accuracy: 84.11%\n",
      "Epoch 751/800, Train Loss: 0.0013, Val Loss: 0.5997, Val Accuracy: 84.11%\n",
      "Epoch 752/800, Train Loss: 0.0002, Val Loss: 0.7530, Val Accuracy: 84.11%\n",
      "Epoch 753/800, Train Loss: 0.0004, Val Loss: 0.6854, Val Accuracy: 83.18%\n",
      "Epoch 754/800, Train Loss: 0.0002, Val Loss: 0.6587, Val Accuracy: 83.18%\n",
      "Epoch 755/800, Train Loss: 0.0011, Val Loss: 0.7078, Val Accuracy: 82.24%\n",
      "Epoch 756/800, Train Loss: 0.0014, Val Loss: 0.6362, Val Accuracy: 81.31%\n",
      "Epoch 757/800, Train Loss: 0.0021, Val Loss: 0.7690, Val Accuracy: 82.24%\n",
      "Epoch 758/800, Train Loss: 0.0021, Val Loss: 0.8778, Val Accuracy: 79.44%\n",
      "Epoch 759/800, Train Loss: 0.0046, Val Loss: 0.8657, Val Accuracy: 81.31%\n",
      "Epoch 760/800, Train Loss: 0.0011, Val Loss: 0.7915, Val Accuracy: 84.11%\n",
      "Epoch 761/800, Train Loss: 0.0029, Val Loss: 0.5967, Val Accuracy: 86.92%\n",
      "Epoch 762/800, Train Loss: 0.0156, Val Loss: 1.2242, Val Accuracy: 72.90%\n",
      "Epoch 763/800, Train Loss: 0.0185, Val Loss: 1.4018, Val Accuracy: 65.42%\n",
      "Epoch 764/800, Train Loss: 0.0358, Val Loss: 0.8825, Val Accuracy: 78.50%\n",
      "Epoch 765/800, Train Loss: 0.0058, Val Loss: 1.1544, Val Accuracy: 73.83%\n",
      "Epoch 766/800, Train Loss: 0.0044, Val Loss: 0.9338, Val Accuracy: 74.77%\n",
      "Epoch 767/800, Train Loss: 0.0024, Val Loss: 0.8100, Val Accuracy: 79.44%\n",
      "Epoch 768/800, Train Loss: 0.0008, Val Loss: 1.1866, Val Accuracy: 69.16%\n",
      "Epoch 769/800, Train Loss: 0.0027, Val Loss: 1.2890, Val Accuracy: 71.96%\n",
      "Epoch 770/800, Train Loss: 0.0009, Val Loss: 1.1440, Val Accuracy: 70.09%\n",
      "Epoch 771/800, Train Loss: 0.0012, Val Loss: 1.1652, Val Accuracy: 72.90%\n",
      "Epoch 772/800, Train Loss: 0.0006, Val Loss: 1.0944, Val Accuracy: 71.03%\n",
      "Epoch 773/800, Train Loss: 0.0004, Val Loss: 1.1995, Val Accuracy: 72.90%\n",
      "Epoch 774/800, Train Loss: 0.0003, Val Loss: 1.0491, Val Accuracy: 74.77%\n",
      "Epoch 775/800, Train Loss: 0.0003, Val Loss: 1.1105, Val Accuracy: 73.83%\n",
      "Epoch 776/800, Train Loss: 0.0010, Val Loss: 1.0353, Val Accuracy: 73.83%\n",
      "Epoch 777/800, Train Loss: 0.0007, Val Loss: 1.0534, Val Accuracy: 74.77%\n",
      "Epoch 778/800, Train Loss: 0.0121, Val Loss: 2.2013, Val Accuracy: 61.68%\n",
      "Epoch 779/800, Train Loss: 0.0283, Val Loss: 1.6846, Val Accuracy: 64.49%\n",
      "Epoch 780/800, Train Loss: 0.0360, Val Loss: 0.8470, Val Accuracy: 77.57%\n",
      "Epoch 781/800, Train Loss: 0.0211, Val Loss: 1.1047, Val Accuracy: 76.64%\n",
      "Epoch 782/800, Train Loss: 0.0157, Val Loss: 0.9735, Val Accuracy: 76.64%\n",
      "Epoch 783/800, Train Loss: 0.0081, Val Loss: 1.0047, Val Accuracy: 73.83%\n",
      "Epoch 784/800, Train Loss: 0.0325, Val Loss: 1.2080, Val Accuracy: 75.70%\n",
      "Epoch 785/800, Train Loss: 0.0056, Val Loss: 0.9954, Val Accuracy: 74.77%\n",
      "Epoch 786/800, Train Loss: 0.0040, Val Loss: 0.8877, Val Accuracy: 78.50%\n",
      "Epoch 787/800, Train Loss: 0.0024, Val Loss: 0.8048, Val Accuracy: 80.37%\n",
      "Epoch 788/800, Train Loss: 0.0004, Val Loss: 0.7682, Val Accuracy: 82.24%\n",
      "Epoch 789/800, Train Loss: 0.0009, Val Loss: 0.7683, Val Accuracy: 81.31%\n",
      "Epoch 790/800, Train Loss: 0.0006, Val Loss: 0.7289, Val Accuracy: 82.24%\n",
      "Epoch 791/800, Train Loss: 0.0192, Val Loss: 0.7791, Val Accuracy: 79.44%\n",
      "Epoch 792/800, Train Loss: 0.0192, Val Loss: 1.9273, Val Accuracy: 65.42%\n",
      "Epoch 793/800, Train Loss: 0.0089, Val Loss: 1.1373, Val Accuracy: 71.96%\n",
      "Epoch 794/800, Train Loss: 0.0084, Val Loss: 1.0735, Val Accuracy: 77.57%\n",
      "Epoch 795/800, Train Loss: 0.0151, Val Loss: 1.4781, Val Accuracy: 72.90%\n",
      "Epoch 796/800, Train Loss: 0.0117, Val Loss: 1.6765, Val Accuracy: 70.09%\n",
      "Epoch 797/800, Train Loss: 0.0041, Val Loss: 0.9908, Val Accuracy: 77.57%\n",
      "Epoch 798/800, Train Loss: 0.0004, Val Loss: 0.9328, Val Accuracy: 78.50%\n",
      "Epoch 799/800, Train Loss: 0.0011, Val Loss: 0.9443, Val Accuracy: 76.64%\n",
      "Epoch 800/800, Train Loss: 0.0006, Val Loss: 0.9538, Val Accuracy: 76.64%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "if 'train_loader' in locals() and 'val_loader' in locals():\n",
    "    train_model_fn(model, train_loader, val_loader, criterion, optimizer, epochs=800) # epochs=20 est un exemple, ajustez\n",
    "else:\n",
    "    print(\"train_loader or val_loader not defined. Skipping training. Check previous cells for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447d655",
   "metadata": {
    "papermill": {
     "duration": 0.056174,
     "end_time": "2025-05-08T12:46:55.227168",
     "exception": false,
     "start_time": "2025-05-08T12:46:55.170994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 16. Fonction d'Évaluation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed8e79b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:46:55.340439Z",
     "iopub.status.busy": "2025-05-08T12:46:55.340025Z",
     "iopub.status.idle": "2025-05-08T12:46:55.347231Z",
     "shell.execute_reply": "2025-05-08T12:46:55.346637Z"
    },
    "papermill": {
     "duration": 0.065019,
     "end_time": "2025-05-08T12:46:55.348235",
     "exception": false,
     "start_time": "2025-05-08T12:46:55.283216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model_fn(model, val_loader, label_encoder):\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for mel_specs, labels in val_loader:\n",
    "            mel_specs, labels = mel_specs.to(device), labels.to(device)\n",
    "            outputs = model(mel_specs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    if not all_labels or not all_preds:\n",
    "        print(\"No labels or predictions to evaluate.\")\n",
    "        return\n",
    "        \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Final Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Afficher les prédictions pour quelques exemples (optionnel)\n",
    "    if len(all_labels) > 0 and len(all_preds) > 0 and label_encoder is not None:\n",
    "        print(\"\\nSample predictions (true vs predicted):\")\n",
    "        for i in range(min(10, len(all_labels))):\n",
    "            try:\n",
    "                true_label_str = label_encoder.inverse_transform([all_labels[i]])[0]\n",
    "                pred_label_str = label_encoder.inverse_transform([all_preds[i]])[0]\n",
    "                print(f\"Sample {i+1}: True='{true_label_str}', Predicted='{pred_label_str}'\")\n",
    "            except IndexError as e:\n",
    "                print(f\"Error decoding labels for sample {i+1}: {e}. Raw labels: True={all_labels[i]}, Pred={all_preds[i]}\")\n",
    "            except Exception as e:\n",
    "                 print(f\"An unexpected error occurred while decoding labels: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4fdb1",
   "metadata": {
    "papermill": {
     "duration": 0.055168,
     "end_time": "2025-05-08T12:46:55.461527",
     "exception": false,
     "start_time": "2025-05-08T12:46:55.406359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 17. Exécution de l'Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac18fd91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:46:55.572658Z",
     "iopub.status.busy": "2025-05-08T12:46:55.572424Z",
     "iopub.status.idle": "2025-05-08T12:46:55.830366Z",
     "shell.execute_reply": "2025-05-08T12:46:55.829530Z"
    },
    "papermill": {
     "duration": 0.315036,
     "end_time": "2025-05-08T12:46:55.831539",
     "exception": false,
     "start_time": "2025-05-08T12:46:55.516503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n",
      "Final Validation Accuracy: 76.64%\n",
      "\n",
      "Sample predictions (true vs predicted):\n",
      "Sample 1: True='angry', Predicted='angry'\n",
      "Sample 2: True='fear', Predicted='fear'\n",
      "Sample 3: True='boredom', Predicted='boredom'\n",
      "Sample 4: True='fear', Predicted='fear'\n",
      "Sample 5: True='angry', Predicted='angry'\n",
      "Sample 6: True='angry', Predicted='angry'\n",
      "Sample 7: True='neutral', Predicted='neutral'\n",
      "Sample 8: True='happy', Predicted='happy'\n",
      "Sample 9: True='angry', Predicted='angry'\n",
      "Sample 10: True='sad', Predicted='sad'\n",
      "\n",
      "Notebook execution finished.\n"
     ]
    }
   ],
   "source": [
    "if 'val_loader' in locals() and 'label_encoder' in locals():\n",
    "    evaluate_model_fn(model, val_loader, label_encoder)\n",
    "else:\n",
    "    print(\"val_loader or label_encoder not defined. Skipping evaluation.\")\n",
    "\n",
    "print(\"\\nNotebook execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2921.525862,
   "end_time": "2025-05-08T12:46:58.368809",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-08T11:58:16.842947",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
